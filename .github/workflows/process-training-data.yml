name: Process Training Data

on:
  workflow_dispatch:
  push:
    paths:
      - "NEPTUN/datasets/jsonl"
    branches:
      - main

permissions:
  contents: write
  packages: read

jobs:
  process-and-release:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11.2"

      - name: Install Poetry
        run: |
          curl -sSL https://install.python-poetry.org | python3 -

      - name: Install dependencies
        working-directory: NEPTUN/scripts
        run: poetry install

      - name: Combine JSONL files
        working-directory: NEPTUN/run
        run: |
          chmod +x combine-training-data-jsonl.sh
          ./combine-training-data-jsonl.sh

      - name: Process training data
        working-directory: NEPTUN/run
        run: |
          chmod +x generate-training-data-binaries.sh
          ./generate-training-data-binaries.sh

      - name: Create Release
        id: create_release
        uses: softprops/action-gh-release@v1
        with:
          files: |
            NEPTUN/datasets/processed/training-data.bin
            NEPTUN/datasets/processed/training-data.idx
            NEPTUN/datasets/training-data.jsonl
            RWKV/FineTuning/tokenizer/rwkv_vocab_v20230424.txt
          tag_name: training-data-${{ github.sha }}
          name: Training Data ${{ github.sha }}
          body: |
            Automatically processed training data
            Commit: ${{ github.sha }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
