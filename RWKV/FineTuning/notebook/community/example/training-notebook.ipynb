{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example title of your finetune / training project\n",
    "\n",
    "Describe your project here in overall\n",
    "\n",
    "Modify the `training-config.yaml` according to your use case\n",
    "\n",
    "Your Discord handle: @your-discord-handle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project setup and initialization\n",
    "\n",
    "> !!! Change the project prefix to something sutible for your project \n",
    ">\n",
    "> !!! Change the model download code / model init code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project prefix, for wandb and filename logging\n",
    "# follow the format of \"dicordhandle\"-\"shortprojectname\"\n",
    "PROJECT_PREFIX=\"userhandle-example-finetune-proj\"\n",
    "\n",
    "# Model version you are using, use v5 or v4 respectively\n",
    "MODEL_VERSION=\"v4\"\n",
    "\n",
    "# Deepspeed strategy to use, you can leave this unchanged\n",
    "DEEPSPEED_STRAT=\"deepspeed_stage_1\"\n",
    "GPU_DEVICES=\"auto\"\n",
    "ENABLE_WANDB=True\n",
    "\n",
    "# Prefixes we will be using\n",
    "WANDB_PREFIX=f\"{PROJECT_PREFIX}\"\n",
    "FILENAME_PREFIX=f\"{PROJECT_PREFIX}\"\n",
    "\n",
    "print(\"DEEPSPEED_STRAT:\", DEEPSPEED_STRAT)\n",
    "print(\"ENABLE_WANDB:\", ENABLE_WANDB)\n",
    "print(\"GPU_DEVICES:\", GPU_DEVICES)\\\n",
    "\n",
    "if ENABLE_WANDB:\n",
    "    WANDB_MODE=\"online\"\n",
    "else:\n",
    "    WANDB_MODE=\"disabled\"\n",
    "\n",
    "# Computing the notebook, and various paths\n",
    "import os\n",
    "NOTEBOOK_DIR=os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "PROJECT_DIR=os.path.abspath(os.path.join(NOTEBOOK_DIR, \"../../../\"))\n",
    "TRAINER_DIR=os.path.abspath(os.path.join(PROJECT_DIR, f\"./RWKV-{MODEL_VERSION}/\"))\n",
    "INFERENCE_DIR=os.path.abspath(os.path.join(PROJECT_DIR, f\"./RWKV-{MODEL_VERSION}/\"))\n",
    "\n",
    "print(\"NOTEBOOK_DIR:\", NOTEBOOK_DIR)\n",
    "print(\"INFERENCE_DIR:\", INFERENCE_DIR)\n",
    "print(\"TRAINER_DIR:\", TRAINER_DIR)\n",
    "print(\"PROJECT_DIR:\", PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the required project directories\n",
    "!mkdir -p \"{PROJECT_DIR}/model/\"\n",
    "!mkdir -p \"{PROJECT_DIR}/datapath/\"\n",
    "!mkdir -p \"{PROJECT_DIR}/checkpoint/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# MODIFY TO EITHER INITIALIZE A NEW MODEL, OR FINE-TUNE AN EXISTING MODEL\n",
    "# AND FINALIZE THE INIT MODEL NAME YOU ARE FINETUNING FROM\n",
    "#\n",
    "\n",
    "# Download an existing model to finetune\n",
    "!cd \"{PROJECT_DIR}/model/\" && \\\n",
    "    wget -nc https://huggingface.co/BlinkDL/rwkv-4-world/resolve/main/RWKV-4-World-1.5B-v1-fixed-20230612-ctx4096.pth\n",
    "\n",
    "# # OR initialize a new model accordingly\n",
    "# !cd \"{TRAINER_DIR}\" && \\\n",
    "#     python3 ./init_model.py \\\n",
    "#         --n_layer 24 --n_embd 2048 \\\n",
    "#         --vocab_size neox --skip-if-exists \\\n",
    "#         \"../model/L24-D2048-neox-init.pth\"\n",
    "\n",
    "# Configure the initial model name you are using\n",
    "INIT_MODEL_NAME=\"RWKV-4-World-1.5B-v1-fixed-20230612-ctx4096.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preloading the dataset\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python3 preload_datapath.py \"{NOTEBOOK_DIR}/training-config.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    export WANDB_MODE=\"{WANDB_MODE}\" && \\\n",
    "    python lightning_trainer.py fit \\\n",
    "        -c \"{NOTEBOOK_DIR}/training-config.yaml\" \\\n",
    "        --trainer.logger.init_args.name=\"{WANDB_PREFIX} training ({DEEPSPEED_STRAT})\" \\\n",
    "        --trainer.strategy=\"{DEEPSPEED_STRAT}\" \\\n",
    "        --trainer.devices=\"{GPU_DEVICES}\" \\\n",
    "        --trainer.callbacks.init_args.dirpath=\"../checkpoint/RWKV-community-training/\" \\\n",
    "        --model.load_model=\"../model/{INIT_MODEL_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets export the model from the checkpoint\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python export_checkpoint.py \"../checkpoint/RWKV-community-training/last.ckpt\" \"../model/{FILENAME_PREFIX}.pth\"\n",
    "!cd \"{TRAINER_DIR}\" && ls -alh \"../model/{FILENAME_PREFIX}.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lets do a quick dragon prompt validation\n",
    "!cd \"{INFERENCE_DIR}\" && \\\n",
    "    python3 dragon_test.py \"../model/{FILENAME_PREFIX}.pth\" \"cuda fp32\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
