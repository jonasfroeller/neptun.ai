{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eagle 7B : Finetuning on various OSS instruct\n",
    "\n",
    "The following showcases an example of Training the RWKV-v5 7B model, on enwiki and various instruct dataset\n",
    "\n",
    "## Configure the env variable below\n",
    "The default auto strategy, should work on a single 4090, scaling up all the way to 8xH100s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU_COUNT: 8\n",
      "GPU_0_VRAM_SIZE (GB): 79.10943603515625\n",
      "ENABLE_WANDB: True\n",
      "GPU_DEVICES: auto\n",
      "DEEPSPEED_STRAT: deepspeed_stage_2\n",
      "TRAINING_CTX_LEN: 4096\n",
      "NOTEBOOK_DIR: /workspace/picocreator/RWKV-infctx-trainer/notebook/finetune-example\n",
      "TRAINER_DIR: /workspace/picocreator/RWKV-infctx-trainer/RWKV-v5\n",
      "PROJECT_DIR: /workspace/picocreator/RWKV-infctx-trainer\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# Your configurable settings\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "# WANDB settings\n",
    "ENABLE_WANDB=True\n",
    "WANDB_PREFIX=\"RWKV-v5-Finetune\"\n",
    "WANDB_PROJECT=\"RWKV-v5-Finetune\"\n",
    "\n",
    "# Project directory offset (you need to modify if, you move the notebook into another dir)\n",
    "PROJECT_DIR_OFFSET=\"../../\"\n",
    "\n",
    "# Config dir (relative to the notebook, excluding ending slash)\n",
    "# to use, with the config filename\n",
    "CONFIG_FILE_DIR=\".\"\n",
    "CONFIG_FILE_NAME=\"Eagle-x-zMultipack-Instruct\"\n",
    "\n",
    "# The model to use\n",
    "MODEL_NAME=\"RWKV-v5-Eagle-World-7B-v2-20240128-ctx4096.pth\"\n",
    "MODEL_URL=\"https://huggingface.co/RWKV/v5-Eagle-7B/resolve/main/RWKV-v5-Eagle-World-7B-v2-20240128-ctx4096.pth?download=true\"\n",
    "\n",
    "# GPU count to use\n",
    "GPU_DEVICES=\"auto\"\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# Lets detect the GPU vram sizes, and suggest a resonable default\n",
    "# based on the detected VRAM sizes\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "# Default settings\n",
    "# NOTE: If your not using cuda, you may want to manually change this around\n",
    "DEEPSPEED_STRAT=\"deepspeed_stage_2\"\n",
    "TRAINING_CTX_LEN=2048\n",
    "MICROBATCH_SIZE=1\n",
    "\n",
    "import torch\n",
    "if torch.cuda is None or not torch.cuda.is_available() or torch.cuda.device_count() <= 0:\n",
    "    print(\"No CUDA compatible GPU found, using default settings\")\n",
    "else:\n",
    "    # -----------------------------------------------------------------\n",
    "    # Auto select the strategy based on the detected VRAM size\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    GPU_COUNT=torch.cuda.device_count()\n",
    "    GPU_0_VRAM_SIZE_GB=torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    if GPU_DEVICES != \"auto\":\n",
    "        GPU_COUNT=int(GPU_DEVICES)\n",
    "    print(\"GPU_COUNT:\", GPU_COUNT)\n",
    "    print(\"GPU_0_VRAM_SIZE (GB):\", GPU_0_VRAM_SIZE_GB)\n",
    "\n",
    "    if GPU_0_VRAM_SIZE_GB < 17:\n",
    "        assert False, \"For the Eagle-7B model, you need atleast 18GB vram\"\n",
    "    elif GPU_0_VRAM_SIZE_GB < 23:\n",
    "        # This takes about 17.5GB vram on a single GPU\n",
    "        # We DO NOT recommend training with ctx_len=128, as the training\n",
    "        # quality will degrade noticably. But it will work!\n",
    "        DEEPSPEED_STRAT=\"deepspeed_stage_2_offload\"\n",
    "        TRAINING_CTX_LEN=128\n",
    "        MICROBATCH_SIZE=1\n",
    "    elif GPU_0_VRAM_SIZE_GB < 25:\n",
    "        # This takes about 21GB vram on a single GPU\n",
    "        DEEPSPEED_STRAT=\"deepspeed_stage_2_offload\"\n",
    "        TRAINING_CTX_LEN=2048\n",
    "        MICROBATCH_SIZE=2\n",
    "    elif GPU_0_VRAM_SIZE_GB < 78:\n",
    "        # This takes about 23GB vram on a single GPU\n",
    "        DEEPSPEED_STRAT=\"deepspeed_stage_2\"\n",
    "        TRAINING_CTX_LEN=4096\n",
    "        MICROBATCH_SIZE=2\n",
    "        if GPU_COUNT >= 8:\n",
    "            MICROBATCH_SIZE=4\n",
    "    else:\n",
    "        # This is now the 80GB vram class\n",
    "        DEEPSPEED_STRAT=\"deepspeed_stage_2\"\n",
    "        TRAINING_CTX_LEN=4096\n",
    "        MICROBATCH_SIZE=4\n",
    "        if GPU_COUNT >= 8:\n",
    "            MICROBATCH_SIZE=8\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# # Training settings you can use to override the \"auto\" default above\n",
    "# -----------------------------------------------------------------\n",
    "# DEEPSPEED_STRAT=\"deepspeed_stage_1\"\n",
    "# TRAINING_CTX_LEN=4096\n",
    "# MICROBATCH_SIZE=8\n",
    "\n",
    "# ---\n",
    "print(\"ENABLE_WANDB:\", ENABLE_WANDB)\n",
    "print(\"GPU_DEVICES:\", GPU_DEVICES)\n",
    "print(\"DEEPSPEED_STRAT:\", DEEPSPEED_STRAT)\n",
    "print(\"TRAINING_CTX_LEN:\", TRAINING_CTX_LEN)\n",
    "if ENABLE_WANDB:\n",
    "    WANDB_MODE=\"online\"\n",
    "else:\n",
    "    WANDB_MODE=\"disabled\"\n",
    "\n",
    "# Computing the notebook, and various paths\n",
    "import os\n",
    "NOTEBOOK_DIR=os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "PROJECT_DIR=os.path.abspath(os.path.join(NOTEBOOK_DIR, PROJECT_DIR_OFFSET))\n",
    "TRAINER_DIR=os.path.abspath(os.path.join(PROJECT_DIR, \"./RWKV-v5/\"))\n",
    "print(\"NOTEBOOK_DIR:\", NOTEBOOK_DIR)\n",
    "print(\"TRAINER_DIR:\", TRAINER_DIR)\n",
    "print(\"PROJECT_DIR:\", PROJECT_DIR)\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(TRAINER_DIR):\n",
    "    raise Exception(\"The trainer directory does not exists. Did you move the notebook?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘RWKV-v5-Eagle-World-7B-v2-20240128-ctx4096.pth’ already there; not retrieving.\n"
     ]
    }
   ],
   "source": [
    "!cd \"{PROJECT_DIR}\" && mkdir -p \"./model\" && \\\n",
    "    cd \"./model\" && \\\n",
    "    wget -nc \"{MODEL_URL}\" -O \"{MODEL_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Starting datapack build process for: /workspace/picocreator/RWKV-infctx-trainer/notebook/finetune-example/./Eagle-x-zMultipack-Instruct-build.yaml\n",
      ">> Preparing dataset - index:  0  - name:  MedText\n",
      "Saving the dataset (1/1 shards): 100%|█| 160/160 [00:00<00:00, 4500.45 examples/\n",
      "Saving the dataset (1/1 shards): 100%|██| 15/15 [00:00<00:00, 734.83 examples/s]\n",
      ">> Preparing dataset - index:  1  - name:  ALMA-prompt-completion\n",
      "Saving the dataset (1/1 shards): 100%|█| 376/376 [00:00<00:00, 1536.56 examples/\n",
      "Saving the dataset (1/1 shards): 100%|█| 1175/1175 [00:00<00:00, 36713.48 exampl\n",
      ">> Preparing dataset - index:  2  - name:  OpenOrca\n",
      "Saving the dataset (20/20 shards): 100%|█| 48493/48493 [00:29<00:00, 1632.41 exa\n",
      "Saving the dataset (1/1 shards): 100%|█| 42340/42340 [00:00<00:00, 50486.14 exam\n",
      ">> Preparing dataset - index:  3  - name:  openhermes-1-instruct\n",
      "Saving the dataset (1/1 shards): 100%|█| 2381/2381 [00:01<00:00, 1573.62 example\n",
      "Saving the dataset (1/1 shards): 100%|█| 2429/2429 [00:00<00:00, 36323.06 exampl\n",
      ">> Preparing dataset - index:  4  - name:  openhermes-2-convo\n",
      "Saving the dataset (5/5 shards): 100%|█| 11659/11659 [00:07<00:00, 1622.38 examp\n",
      "Saving the dataset (1/1 shards): 100%|█| 10016/10016 [00:00<00:00, 45300.85 exam\n",
      ">> Preparing dataset - index:  5  - name:  Capybara-chat\n",
      "Saving the dataset (1/1 shards): 100%|█| 546/546 [00:00<00:00, 1662.83 examples/\n",
      "Saving the dataset (1/1 shards): 100%|█| 161/161 [00:00<00:00, 5270.87 examples/\n",
      ">> Preparing dataset - index:  6  - name:  Pure-Dove\n",
      "Saving the dataset (1/1 shards): 100%|█| 160/160 [00:00<00:00, 1803.69 examples/\n",
      "Saving the dataset (1/1 shards): 100%|█| 39/39 [00:00<00:00, 1645.14 examples/s]\n",
      ">> Preparing dataset - index:  7  - name:  Lamini-instructions-to-french\n",
      "Saving the dataset (1/1 shards): 100%|█| 160/160 [00:00<00:00, 2280.34 examples/\n",
      "Saving the dataset (1/1 shards): 100%|█| 100/100 [00:00<00:00, 4150.72 examples/\n",
      ">> Preparing dataset - index:  8  - name:  LongAlign-10k\n",
      "Map (num_proc=160): 100%|██████████| 9888/9888 [00:06<00:00, 1591.33 examples/s]\n",
      "Filter (num_proc=160): 100%|███████| 9888/9888 [00:02<00:00, 3729.92 examples/s]\n",
      "Map (num_proc=160): 100%|██████████| 8662/8662 [00:02<00:00, 2903.49 examples/s]\n",
      "Map (num_proc=160): 100%|██████████| 8662/8662 [00:03<00:00, 2281.36 examples/s]\n",
      "Saving the dataset (2/2 shards): 100%|█| 4191/4191 [00:03<00:00, 1056.44 example\n",
      "Saving the dataset (1/1 shards): 100%|█| 88/88 [00:00<00:00, 1509.03 examples/s]\n",
      ">> Dataset Mixing mode:  shuffle\n",
      ">> Saving dataset to data_path :  /datapath/world/Eagle-x-Instruct/\n",
      "Saving the dataset (27/27 shards): 100%|█| 68126/68126 [00:43<00:00, 1550.93 exa\n",
      "Saving the dataset (1/1 shards): 100%|█| 56363/56363 [00:00<00:00, 61522.92 exam\n",
      ">> Dataset saved to data_path\n",
      ">> -----------------------------------\n",
      ">> Performing dataset counting\n",
      ">> -----------------------------------\n",
      ">> Final dataset count ( train ) : 68,126  samples/chunks/packs\n",
      ">> Final dataset count ( test  ) : 56,363  samples\n",
      ">> -----------------------------------\n",
      "Map (num_proc=160): 100%|████████| 68126/68126 [00:34<00:00, 1957.21 examples/s]\n",
      "Map (num_proc=160): 100%|████████| 56363/56363 [00:17<00:00, 3274.37 examples/s]\n",
      ">> -----------------------------------\n",
      ">> Final 'train' dataset token count ...\n",
      ">> - Total tokens : 2,192,472,687\n",
      ">> - Valid tokens : 790,723,014\n",
      ">> - Hidden tokens : 1,401,749,673\n",
      ">> -----------------------------------\n",
      ">> Final 'test' dataset token count ...\n",
      ">> - Total tokens : 22,156,465\n",
      ">> - Valid tokens : 7,883,712\n",
      ">> - Hidden tokens : 14,272,753\n",
      ">> -----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lets build the giant datapack\n",
    "!cd \"{TRAINER_DIR}\" && python3 datapack_build.py \"{NOTEBOOK_DIR}/{CONFIG_FILE_DIR}/{CONFIG_FILE_NAME}-build.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the initial validation run (for reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-06 05:15:39,276] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.1+cu121'\n",
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/cli.py:518: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['validate', '-c', '/workspace/picocreator/RWKV-infctx-trainer/notebook/finetune-example/./Eagle-x-zMultipack-Instruct.yaml', '--model.load_model=../model/RWKV-v5-Eagle-World-7B-v2-20240128-ctx4096.pth', '--data.skip_datapath_setup=True', '--trainer.logger.init_args.name=RWKV-v5-Finetune - Eagle-x-zMultipack-Instruct (tctxlen=4096, deepspeed_stage_2)', '--trainer.logger.init_args.project=RWKV-v5-Finetune', '--trainer.strategy=deepspeed_stage_2', '--trainer.target_batch_size=1024', '--trainer.microbatch_size=8', '--model.ctx_len=4096', '--trainer.devices=auto'], args=['validate', '-c', '/workspace/picocreator/RWKV-infctx-trainer/notebook/finetune-example/./Eagle-x-zMultipack-Instruct.yaml', '--model.load_model=../model/RWKV-v5-Eagle-World-7B-v2-20240128-ctx4096.pth', '--data.skip_datapath_setup=True', '--trainer.logger.init_args.name=RWKV-v5-Finetune - Eagle-x-zMultipack-Instruct (tctxlen=4096, deepspeed_stage_2)', '--trainer.logger.init_args.project=RWKV-v5-Finetune', '--trainer.strategy=deepspeed_stage_2', '--trainer.target_batch_size=1024', '--trainer.microbatch_size=8', '--model.ctx_len=4096', '--trainer.devices=auto'].\n",
      "/usr/local/lib/python3.10/dist-packages/lightning/fabric/utilities/seed.py:40: No seed found, seed set to 1159755060\n",
      "Seed set to 1159755060\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "---\n",
      "[RWKV.TimeMix] Compiling CUDA kernel with HEAD_SIZE=64\n",
      "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/wkv5/build.ninja...\n",
      "Building extension module wkv5...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module wkv5...\n",
      "[RWKV.TimeMix] CUDA kernel compiled & loaded globally\n",
      "---\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "\n",
      "[RWKV.Trainer] Applying 'target_batch_size' with the following:\n",
      "   - target_batch_size:       1024\n",
      "   - num_nodes:               1\n",
      "   - num_devices:             8\n",
      "   - microbatch_size:         8\n",
      "   - accumulate_grad_batches: 16\n",
      "   - effective_batch_size:    1024\n",
      "\n",
      "[rank: 0] Seed set to 1159755060\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/8\n",
      "[2024-02-06 05:16:20,194] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-02-06 05:16:20,383] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-02-06 05:16:20,390] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-02-06 05:16:20,429] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-02-06 05:16:20,479] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-02-06 05:16:20,487] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-02-06 05:16:20,511] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.1+cu121'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.1+cu121'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.1+cu121'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.1+cu121'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.1+cu121'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.1+cu121'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.1+cu121'\n",
      "[rank: 4] Seed set to 1159755060\n",
      "[rank: 2] Seed set to 1159755060\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 7] Seed set to 1159755060\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 3] Seed set to 1159755060\n",
      "[rank: 1] Seed set to 1159755060\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 6] Seed set to 1159755060\n",
      "[rank: 5] Seed set to 1159755060\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "---\n",
      "[RWKV.TimeMix] Compiling CUDA kernel with HEAD_SIZE=64\n",
      "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/wkv5/build.ninja...\n",
      "---\n",
      "[RWKV.TimeMix] Compiling CUDA kernel with HEAD_SIZE=64\n",
      "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "---\n",
      "[RWKV.TimeMix] Compiling CUDA kernel with HEAD_SIZE=64\n",
      "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "---\n",
      "[RWKV.TimeMix] Compiling CUDA kernel with HEAD_SIZE=64\n",
      "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "---\n",
      "[RWKV.TimeMix] Compiling CUDA kernel with HEAD_SIZE=64\n",
      "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "---\n",
      "[RWKV.TimeMix] Compiling CUDA kernel with HEAD_SIZE=64\n",
      "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "---\n",
      "[RWKV.TimeMix] Compiling CUDA kernel with HEAD_SIZE=64\n",
      "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "Building extension module wkv5...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module wkv5...\n",
      "[RWKV.TimeMix] CUDA kernel compiled & loaded globally\n",
      "---\n",
      "Loading extension module wkv5...\n",
      "[RWKV.TimeMix] CUDA kernel compiled & loaded globally\n",
      "---\n",
      "Loading extension module wkv5...\n",
      "[RWKV.TimeMix] CUDA kernel compiled & loaded globally\n",
      "---\n",
      "Loading extension module wkv5...\n",
      "[RWKV.TimeMix] CUDA kernel compiled & loaded globally\n",
      "---\n",
      "Loading extension module wkv5...\n",
      "[RWKV.TimeMix] CUDA kernel compiled & loaded globally\n",
      "---\n",
      "Loading extension module wkv5...\n",
      "[RWKV.TimeMix] CUDA kernel compiled & loaded globally\n",
      "---\n",
      "Loading extension module wkv5...\n",
      "[RWKV.TimeMix] CUDA kernel compiled & loaded globally\n",
      "---\n",
      "[rank: 3] Seed set to 1159755060\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/8\n",
      "[rank: 2] Seed set to 1159755060\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/8\n",
      "[rank: 4] Seed set to 1159755060\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 4, MEMBER: 5/8\n",
      "[rank: 7] Seed set to 1159755060\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 7, MEMBER: 8/8\n",
      "[rank: 6] Seed set to 1159755060\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 6, MEMBER: 7/8\n",
      "[rank: 1] Seed set to 1159755060\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/8\n",
      "[rank: 5] Seed set to 1159755060\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 5, MEMBER: 6/8\n",
      "Enabling DeepSpeed BF16. Model parameters and inputs will be cast to `bfloat16`.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpicocreator\u001b[0m (\u001b[33mrwkv-x-dev\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./wandb/run-20240206_051721-y2fbiqbc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mRWKV-v5-Finetune - Eagle-x-zMultipack-Instruct (tctxlen=4096, deepspeed_stage_2)\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-v5-Finetune\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-v5-Finetune/runs/y2fbiqbc\u001b[0m\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "Validation DataLoader 0: 100%|████████████████| 881/881 [06:02<00:00,  2.43it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "     validation/loss         1.270364761352539\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.024 MB of 0.024 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                batchidx ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   epoch ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             global_rank ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     trainer/global_step ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  validation/data_ctxlen ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    validation/data_loss ▅▁▅▃▂▅▃▁▆▃▂▅▁▄▁█▁▂▄▆▅▃▃▃▄▃▃▄▄▃▃▃▃▁▂▃▄▃▄▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation/learn_loss ▅▁▅▃▂▅▃▁▆▃▂▅▁▄▁█▁▂▄▆▅▃▃▃▄▃▃▄▄▃▃▃▃▁▂▃▄▃▄▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: validation/learn_tokens ▁▅▃▄▅▅▃▃▃▂▆▅▃▂▄▁▅▃▂▂▄▂▂▃▅▃▂▃▃▄▂▄▄▄█▇▅█▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         validation/loss ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                batchidx 880\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   epoch 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             global_rank 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     trainer/global_step 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  validation/data_ctxlen 26631\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    validation/data_loss 1.55469\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   validation/learn_loss 1.55469\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: validation/learn_tokens 1010\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         validation/loss 1.27036\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mRWKV-v5-Finetune - Eagle-x-zMultipack-Instruct (tctxlen=4096, deepspeed_stage_2)\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-v5-Finetune/runs/y2fbiqbc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ️⚡ View job at \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-v5-Finetune/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEzNTU3NTUxNw==/version_details/v14\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240206_051721-y2fbiqbc/logs\u001b[0m\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Setup the checkpoint dir\n",
    "!cd \"{PROJECT_DIR}\" && mkdir -p \"./checkpoint/{CONFIG_FILE_NAME}/\"\n",
    "\n",
    "# Lets start the training\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    export RWKV_NO_CUDA=0 && \\\n",
    "    export RWKV_TORCH_COMPILE=0 && \\\n",
    "    export WANDB_MODE=\"{WANDB_MODE}\" && \\\n",
    "    python3 lightning_trainer.py validate \\\n",
    "        -c \"{NOTEBOOK_DIR}/{CONFIG_FILE_DIR}/{CONFIG_FILE_NAME}.yaml\" \\\n",
    "        --model.load_model=\"../model/{MODEL_NAME}\" \\\n",
    "        --data.skip_datapath_setup=True \\\n",
    "        --trainer.logger.init_args.name=\"{WANDB_PREFIX} - {CONFIG_FILE_NAME} (tctxlen={TRAINING_CTX_LEN}, {DEEPSPEED_STRAT})\" \\\n",
    "        --trainer.logger.init_args.project=\"{WANDB_PROJECT}\" \\\n",
    "        --trainer.strategy=\"{DEEPSPEED_STRAT}\" \\\n",
    "        --trainer.target_batch_size=1024 \\\n",
    "        --trainer.microbatch_size={MICROBATCH_SIZE} \\\n",
    "        --model.ctx_len={TRAINING_CTX_LEN} \\\n",
    "        --trainer.devices=\"{GPU_DEVICES}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the training run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-06 22:08:40,160] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.1+cu121'\n",
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/cli.py:518: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['fit', '-c', '/workspace/picocreator/RWKV-infctx-trainer/notebook/finetune-example/./Eagle-x-zMultipack-Instruct.yaml', '--model.load_model=../model/RWKV-v5-Eagle-World-7B-v2-20240128-ctx4096.pth', '--data.skip_datapath_setup=True', '--trainer.logger.init_args.name=RWKV-v5-Finetune - Eagle-x-zMultipack-Instruct (tctxlen=4096, deepspeed_stage_2)', '--trainer.logger.init_args.project=RWKV-v5-Finetune', '--trainer.strategy=deepspeed_stage_2', '--trainer.target_batch_size=1024', '--trainer.microbatch_size=8', '--model.ctx_len=4096', '--trainer.devices=auto'], args=['fit', '-c', '/workspace/picocreator/RWKV-infctx-trainer/notebook/finetune-example/./Eagle-x-zMultipack-Instruct.yaml', '--model.load_model=../model/RWKV-v5-Eagle-World-7B-v2-20240128-ctx4096.pth', '--data.skip_datapath_setup=True', '--trainer.logger.init_args.name=RWKV-v5-Finetune - Eagle-x-zMultipack-Instruct (tctxlen=4096, deepspeed_stage_2)', '--trainer.logger.init_args.project=RWKV-v5-Finetune', '--trainer.strategy=deepspeed_stage_2', '--trainer.target_batch_size=1024', '--trainer.microbatch_size=8', '--model.ctx_len=4096', '--trainer.devices=auto'].\n",
      "/usr/local/lib/python3.10/dist-packages/lightning/fabric/utilities/seed.py:40: No seed found, seed set to 1978833166\n",
      "Seed set to 1978833166\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "\n",
      "[RWKV.Trainer] Applying 'target_batch_size' with the following:\n",
      "   - target_batch_size:       1024\n",
      "   - num_nodes:               4\n",
      "   - num_devices:             8\n",
      "   - microbatch_size:         8\n",
      "   - accumulate_grad_batches: 4\n",
      "   - effective_batch_size:    1024\n",
      "\n",
      "[rank: 0] Seed set to 1978833166\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/32\n",
      "[2024-02-06 22:09:21,651] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-02-06 22:09:21,689] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-02-06 22:09:21,729] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-02-06 22:09:21,731] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-02-06 22:09:21,754] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-02-06 22:09:21,812] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-02-06 22:09:21,840] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.1+cu121'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.1+cu121'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.1+cu121'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.1+cu121'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.1+cu121'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.1+cu121'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.1+cu121'\n",
      "[rank: 2] Seed set to 1978833166\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 7] Seed set to 1978833166\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 3] Seed set to 1978833166\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 1] Seed set to 1978833166\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 4] Seed set to 1978833166\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 6] Seed set to 1978833166\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 5] Seed set to 1978833166\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 4] Seed set to 1978833166\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 4, MEMBER: 5/32\n",
      "[rank: 3] Seed set to 1978833166\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/32\n",
      "[rank: 1] Seed set to 1978833166\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/32\n",
      "[rank: 2] Seed set to 1978833166\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/32\n",
      "[rank: 5] Seed set to 1978833166\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 5, MEMBER: 6/32\n",
      "[rank: 6] Seed set to 1978833166\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 6, MEMBER: 7/32\n",
      "[rank: 7] Seed set to 1978833166\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 7, MEMBER: 8/32\n",
      "Enabling DeepSpeed BF16. Model parameters and inputs will be cast to `bfloat16`.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpicocreator\u001b[0m (\u001b[33mrwkv-x-dev\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.3 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./wandb/run-20240206_221054-qd3mym90\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mRWKV-v5-Finetune - Eagle-x-zMultipack-Instruct (tctxlen=4096, deepspeed_stage_2)\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-v5-Finetune\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-v5-Finetune/runs/qd3mym90\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:639: Checkpoint directory /checkpoint/big-run/Eagle-x-Instruct exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "#\n",
      "# RWKV lighting_trainer.py important notes \n",
      "# https://github.com/RWKV/RWKV-infctx-trainer \n",
      "#\n",
      "# - Ensure your host is not running cuda 12.0 (use either 11.8, or >=12.1), as this is known to have freeze issues\n",
      "# - The terms used in wandb / the progress bar can be confusing, see the github README.md for beter clarifications\n",
      "# - When resuming from checkpoint, the estimated time is inaccurate\n",
      "#LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "\n",
      "[RWKV.model] Configuring optimizer with\n",
      "    - lr_init:  1.000e-05 (1e-05)\n",
      "    - lr_final: 1.000e-05 (1e-05)\n",
      "\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.04825186729431152 seconds\n",
      "/usr/local/lib/python3.10/dist-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Loading extension module fused_adam...\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.10131430625915527 seconds\n",
      "Loading extension module fused_adam...\n",
      "Loading extension module fused_adam...\n",
      "/usr/local/lib/python3.10/dist-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.10163402557373047 seconds\n",
      "Time to load fused_adam op: 0.10162591934204102 seconds\n",
      "/usr/local/lib/python3.10/dist-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "/usr/local/lib/python3.10/dist-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Time to load fused_adam op: 0.10174846649169922 seconds\n",
      "Loading extension module fused_adam...\n",
      "/usr/local/lib/python3.10/dist-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Time to load fused_adam op: 0.10250639915466309 seconds\n",
      "/usr/local/lib/python3.10/dist-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Time to load fused_adam op: 0.10202169418334961 seconds\n",
      "/usr/local/lib/python3.10/dist-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.10138869285583496 seconds\n",
      "/usr/local/lib/python3.10/dist-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | emb    | Embedding  | 268 M \n",
      "1 | blocks | ModuleList | 7.0 B \n",
      "2 | ln_out | LayerNorm  | 8.2 K \n",
      "3 | head   | Linear     | 268 M \n",
      "--------------------------------------\n",
      "7.5 B     Trainable params\n",
      "0         Non-trainable params\n",
      "7.5 B     Total params\n",
      "30,072.177Total estimated model params size (MB)\n",
      "Restoring states from the checkpoint path at /checkpoint/big-run/Eagle-x-Instruct/last.ckpt/\n",
      "Restored all states from the checkpoint at /checkpoint/big-run/Eagle-x-Instruct/last.ckpt/\n",
      "Epoch 1:   0%|                                          | 0/266 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/training_epoch_loop.py:154: You're resuming from a checkpoint that ended before the epoch ended. This can cause unreliable results if further training is done. Consider using an end-of-epoch checkpoint\n",
      "Epoch 1: 100%|██| 266/266 [18:39<00:00,  0.24it/s, v_num=ym90, train/loss=0.906]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                       | 0/221 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                          | 0/221 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                  | 1/221 [00:01<05:14,  0.70it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏                 | 2/221 [00:01<02:59,  1.22it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏                 | 3/221 [00:01<02:13,  1.64it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎                 | 4/221 [00:02<01:50,  1.97it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▍                 | 5/221 [00:02<01:44,  2.07it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍                 | 6/221 [00:02<01:41,  2.13it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▌                 | 7/221 [00:03<01:40,  2.12it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▋                 | 8/221 [00:04<01:54,  1.87it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▋                 | 9/221 [00:04<01:48,  1.95it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▊                | 10/221 [00:05<01:48,  1.94it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▊                | 11/221 [00:05<01:45,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                | 12/221 [00:05<01:42,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|█                | 13/221 [00:06<01:39,  2.08it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|█                | 14/221 [00:07<01:48,  1.91it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|█▏               | 15/221 [00:07<01:45,  1.95it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|█▏               | 16/221 [00:08<01:43,  1.99it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▎               | 17/221 [00:08<01:41,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▍               | 18/221 [00:09<01:43,  1.97it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▍               | 19/221 [00:09<01:40,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▌               | 20/221 [00:09<01:38,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▌               | 21/221 [00:10<01:37,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▋               | 22/221 [00:10<01:36,  2.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊               | 23/221 [00:11<01:35,  2.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▊               | 24/221 [00:11<01:34,  2.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▉               | 25/221 [00:12<01:35,  2.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|██               | 26/221 [00:12<01:33,  2.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|██               | 27/221 [00:12<01:32,  2.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|██▏              | 28/221 [00:13<01:31,  2.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|██▏              | 29/221 [00:13<01:30,  2.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|██▎              | 30/221 [00:14<01:29,  2.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|██▍              | 31/221 [00:14<01:28,  2.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|██▍              | 32/221 [00:14<01:28,  2.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▌              | 33/221 [00:15<01:27,  2.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▌              | 34/221 [00:16<01:31,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▋              | 35/221 [00:17<01:32,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▊              | 36/221 [00:17<01:32,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▊              | 37/221 [00:18<01:31,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▉              | 38/221 [00:18<01:30,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|███              | 39/221 [00:19<01:29,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|███              | 40/221 [00:20<01:30,  1.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|███▏             | 41/221 [00:20<01:30,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|███▏             | 42/221 [00:20<01:28,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|███▎             | 43/221 [00:21<01:27,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▍             | 44/221 [00:21<01:27,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▍             | 45/221 [00:22<01:26,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|███▌             | 46/221 [00:22<01:26,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|███▌             | 47/221 [00:23<01:25,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▋             | 48/221 [00:23<01:24,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▊             | 49/221 [00:24<01:25,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▊             | 50/221 [00:24<01:24,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▉             | 51/221 [00:25<01:24,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|████             | 52/221 [00:25<01:23,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|████             | 53/221 [00:25<01:22,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|████▏            | 54/221 [00:26<01:21,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▏            | 55/221 [00:26<01:21,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▎            | 56/221 [00:27<01:20,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|████▍            | 57/221 [00:27<01:20,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|████▍            | 58/221 [00:29<01:21,  1.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|████▌            | 59/221 [00:29<01:21,  1.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|████▌            | 60/221 [00:30<01:20,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|████▋            | 61/221 [00:31<01:21,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|████▊            | 62/221 [00:31<01:21,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████▊            | 63/221 [00:31<01:20,  1.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████▉            | 64/221 [00:32<01:19,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|█████            | 65/221 [00:32<01:18,  1.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████            | 66/221 [00:32<01:17,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▏           | 67/221 [00:33<01:16,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|█████▏           | 68/221 [00:33<01:15,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|█████▎           | 69/221 [00:34<01:15,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|█████▍           | 70/221 [00:34<01:14,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|█████▍           | 71/221 [00:34<01:13,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|█████▌           | 72/221 [00:35<01:12,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|█████▌           | 73/221 [00:35<01:12,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|█████▋           | 74/221 [00:36<01:12,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|█████▊           | 75/221 [00:37<01:13,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|█████▊           | 76/221 [00:37<01:12,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|█████▉           | 77/221 [00:38<01:11,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████           | 78/221 [00:39<01:11,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|██████           | 79/221 [00:39<01:11,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|██████▏          | 80/221 [00:39<01:10,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|██████▏          | 81/221 [00:40<01:09,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|██████▎          | 82/221 [00:40<01:09,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|██████▍          | 83/221 [00:41<01:08,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|██████▍          | 84/221 [00:41<01:07,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|██████▌          | 85/221 [00:42<01:08,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|██████▌          | 86/221 [00:42<01:07,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|██████▋          | 87/221 [00:43<01:07,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|██████▊          | 88/221 [00:45<01:08,  1.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|██████▊          | 89/221 [00:45<01:07,  1.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|██████▉          | 90/221 [00:46<01:06,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|███████          | 91/221 [00:46<01:06,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|███████          | 92/221 [00:46<01:05,  1.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|███████▏         | 93/221 [00:47<01:04,  1.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▏         | 94/221 [00:47<01:04,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▎         | 95/221 [00:47<01:03,  1.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▍         | 96/221 [00:48<01:03,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|███████▍         | 97/221 [00:48<01:02,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|███████▌         | 98/221 [00:49<01:02,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|███████▌         | 99/221 [00:49<01:01,  1.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|███████▏        | 100/221 [00:50<01:00,  1.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|███████▎        | 101/221 [00:50<01:00,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|███████▍        | 102/221 [00:51<00:59,  1.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|███████▍        | 103/221 [00:51<00:59,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|███████▌        | 104/221 [00:52<00:58,  1.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|███████▌        | 105/221 [00:53<00:58,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|███████▋        | 106/221 [00:53<00:58,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|███████▋        | 107/221 [00:53<00:57,  1.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|███████▊        | 108/221 [00:54<00:57,  1.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|███████▉        | 109/221 [00:55<00:56,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|███████▉        | 110/221 [00:55<00:55,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|████████        | 111/221 [00:55<00:55,  1.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|████████        | 112/221 [00:57<00:55,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|████████▏       | 113/221 [00:58<00:55,  1.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|████████▎       | 114/221 [00:58<00:55,  1.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|████████▎       | 115/221 [00:59<00:54,  1.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|████████▍       | 116/221 [00:59<00:53,  1.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|████████▍       | 117/221 [00:59<00:53,  1.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|████████▌       | 118/221 [01:00<00:52,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|████████▌       | 119/221 [01:01<00:52,  1.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|████████▋       | 120/221 [01:01<00:51,  1.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|████████▊       | 121/221 [01:02<00:51,  1.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|████████▊       | 122/221 [01:02<00:51,  1.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|████████▉       | 123/221 [01:03<00:50,  1.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|████████▉       | 124/221 [01:03<00:49,  1.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████       | 125/221 [01:04<00:49,  1.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████       | 126/221 [01:04<00:48,  1.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████▏      | 127/221 [01:06<00:48,  1.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|█████████▎      | 128/221 [01:06<00:48,  1.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|█████████▎      | 129/221 [01:06<00:47,  1.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|█████████▍      | 130/221 [01:07<00:47,  1.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|█████████▍      | 131/221 [01:07<00:46,  1.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|█████████▌      | 132/221 [01:08<00:45,  1.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|█████████▋      | 133/221 [01:08<00:45,  1.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|█████████▋      | 134/221 [01:08<00:44,  1.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|█████████▊      | 135/221 [01:09<00:44,  1.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|█████████▊      | 136/221 [01:11<00:44,  1.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|█████████▉      | 137/221 [01:11<00:43,  1.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|█████████▉      | 138/221 [01:12<00:43,  1.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|██████████      | 139/221 [01:12<00:42,  1.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|██████████▏     | 140/221 [01:12<00:42,  1.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|██████████▏     | 141/221 [01:13<00:41,  1.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|██████████▎     | 142/221 [01:13<00:41,  1.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|██████████▎     | 143/221 [01:14<00:40,  1.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|██████████▍     | 144/221 [01:15<00:40,  1.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|██████████▍     | 145/221 [01:15<00:39,  1.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|██████████▌     | 146/221 [01:16<00:39,  1.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████████▋     | 147/221 [01:16<00:38,  1.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████████▋     | 148/221 [01:16<00:37,  1.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████████▊     | 149/221 [01:17<00:37,  1.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|██████████▊     | 150/221 [01:17<00:36,  1.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|██████████▉     | 151/221 [01:17<00:36,  1.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|███████████     | 152/221 [01:18<00:35,  1.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|███████████     | 153/221 [01:18<00:35,  1.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|███████████▏    | 154/221 [01:19<00:34,  1.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|███████████▏    | 155/221 [01:19<00:33,  1.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|███████████▎    | 156/221 [01:20<00:33,  1.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|███████████▎    | 157/221 [01:21<00:33,  1.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|███████████▍    | 158/221 [01:21<00:32,  1.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|███████████▌    | 159/221 [01:22<00:32,  1.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|███████████▌    | 160/221 [01:22<00:31,  1.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|███████████▋    | 161/221 [01:22<00:30,  1.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|███████████▋    | 162/221 [01:23<00:30,  1.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|███████████▊    | 163/221 [01:25<00:30,  1.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|███████████▊    | 164/221 [01:25<00:29,  1.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|███████████▉    | 165/221 [01:26<00:29,  1.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████    | 166/221 [01:26<00:28,  1.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|████████████    | 167/221 [01:26<00:28,  1.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|████████████▏   | 168/221 [01:27<00:27,  1.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|████████████▏   | 169/221 [01:27<00:26,  1.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|████████████▎   | 170/221 [01:28<00:26,  1.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|████████████▍   | 171/221 [01:28<00:25,  1.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|████████████▍   | 172/221 [01:28<00:25,  1.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|████████████▌   | 173/221 [01:29<00:24,  1.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|████████████▌   | 174/221 [01:29<00:24,  1.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|████████████▋   | 175/221 [01:29<00:23,  1.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████████▋   | 176/221 [01:30<00:23,  1.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████████▊   | 177/221 [01:30<00:22,  1.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|████████████▉   | 178/221 [01:31<00:22,  1.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|████████████▉   | 179/221 [01:31<00:21,  1.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|█████████████   | 180/221 [01:32<00:20,  1.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|█████████████   | 181/221 [01:32<00:20,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|█████████████▏  | 182/221 [01:32<00:19,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|█████████████▏  | 183/221 [01:33<00:19,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|█████████████▎  | 184/221 [01:33<00:18,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|█████████████▍  | 185/221 [01:34<00:18,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|█████████████▍  | 186/221 [01:35<00:17,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|█████████████▌  | 187/221 [01:35<00:17,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|█████████████▌  | 188/221 [01:36<00:16,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|█████████████▋  | 189/221 [01:36<00:16,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|█████████████▊  | 190/221 [01:37<00:15,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|█████████████▊  | 191/221 [01:37<00:15,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|█████████████▉  | 192/221 [01:37<00:14,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|█████████████▉  | 193/221 [01:38<00:14,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|██████████████  | 194/221 [01:38<00:13,  1.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|██████████████  | 195/221 [01:39<00:13,  1.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|██████████████▏ | 196/221 [01:39<00:12,  1.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|██████████████▎ | 197/221 [01:39<00:12,  1.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|██████████████▎ | 198/221 [01:40<00:11,  1.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|██████████████▍ | 199/221 [01:40<00:11,  1.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|██████████████▍ | 200/221 [01:41<00:10,  1.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|██████████████▌ | 201/221 [01:41<00:10,  1.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|██████████████▌ | 202/221 [01:42<00:09,  1.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|██████████████▋ | 203/221 [01:42<00:09,  1.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|██████████████▊ | 204/221 [01:43<00:08,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|██████████████▊ | 205/221 [01:44<00:08,  1.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|██████████████▉ | 206/221 [01:44<00:07,  1.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|██████████████▉ | 207/221 [01:44<00:07,  1.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|███████████████ | 208/221 [01:45<00:06,  1.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|███████████████▏| 209/221 [01:45<00:06,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|███████████████▏| 210/221 [01:46<00:05,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|███████████████▎| 211/221 [01:46<00:05,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|███████████████▎| 212/221 [01:47<00:04,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|███████████████▍| 213/221 [01:47<00:04,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|███████████████▍| 214/221 [01:47<00:03,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|███████████████▌| 215/221 [01:48<00:03,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|███████████████▋| 216/221 [01:49<00:02,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|███████████████▋| 217/221 [01:49<00:02,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|███████████████▊| 218/221 [01:50<00:01,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|███████████████▊| 219/221 [01:51<00:01,  1.97it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████▉| 220/221 [01:57<00:00,  1.87it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████| 221/221 [01:59<00:00,  1.85it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 266/266 [20:50<00:00,  0.21it/s, v_num=ym90, train/loss=0.906, \u001b[A/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Epoch 2: 100%|█| 266/266 [3:43:14<00:00,  0.02it/s, v_num=ym90, train/loss=0.863\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                       | 0/221 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                          | 0/221 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                  | 1/221 [00:00<01:15,  2.90it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏                 | 2/221 [00:00<01:01,  3.54it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏                 | 3/221 [00:00<00:55,  3.93it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎                 | 4/221 [00:00<00:52,  4.11it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▍                 | 5/221 [00:01<00:59,  3.63it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍                 | 6/221 [00:01<01:03,  3.36it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▌                 | 7/221 [00:02<01:09,  3.10it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▋                 | 8/221 [00:03<01:26,  2.47it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▋                 | 9/221 [00:03<01:23,  2.54it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▊                | 10/221 [00:04<01:26,  2.44it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▊                | 11/221 [00:04<01:24,  2.47it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                | 12/221 [00:04<01:23,  2.50it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|█                | 13/221 [00:05<01:22,  2.51it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|█                | 14/221 [00:06<01:32,  2.23it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|█▏               | 15/221 [00:06<01:30,  2.27it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|█▏               | 16/221 [00:06<01:29,  2.30it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▎               | 17/221 [00:07<01:28,  2.31it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▍               | 18/221 [00:08<01:30,  2.24it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▍               | 19/221 [00:08<01:28,  2.28it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▌               | 20/221 [00:08<01:27,  2.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▌               | 21/221 [00:09<01:26,  2.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▋               | 22/221 [00:09<01:25,  2.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊               | 23/221 [00:09<01:24,  2.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▊               | 24/221 [00:10<01:24,  2.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▉               | 25/221 [00:10<01:24,  2.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|██               | 26/221 [00:11<01:23,  2.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|██               | 27/221 [00:11<01:22,  2.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|██▏              | 28/221 [00:11<01:21,  2.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|██▏              | 29/221 [00:12<01:21,  2.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|██▎              | 30/221 [00:12<01:20,  2.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|██▍              | 31/221 [00:13<01:20,  2.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|██▍              | 32/221 [00:13<01:19,  2.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▌              | 33/221 [00:13<01:19,  2.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▌              | 34/221 [00:15<01:22,  2.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▋              | 35/221 [00:15<01:23,  2.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▊              | 36/221 [00:16<01:23,  2.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▊              | 37/221 [00:16<01:23,  2.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▉              | 38/221 [00:17<01:22,  2.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|███              | 39/221 [00:17<01:21,  2.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|███              | 40/221 [00:18<01:21,  2.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|███▏             | 41/221 [00:18<01:21,  2.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|███▏             | 42/221 [00:18<01:20,  2.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|███▎             | 43/221 [00:19<01:19,  2.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▍             | 44/221 [00:19<01:18,  2.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▍             | 45/221 [00:19<01:18,  2.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|███▌             | 46/221 [00:20<01:17,  2.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|███▌             | 47/221 [00:20<01:16,  2.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▋             | 48/221 [00:21<01:16,  2.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▊             | 49/221 [00:21<01:16,  2.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▊             | 50/221 [00:22<01:15,  2.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▉             | 51/221 [00:22<01:15,  2.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|████             | 52/221 [00:22<01:14,  2.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|████             | 53/221 [00:23<01:13,  2.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|████▏            | 54/221 [00:23<01:12,  2.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▏            | 55/221 [00:24<01:12,  2.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▎            | 56/221 [00:24<01:12,  2.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|████▍            | 57/221 [00:24<01:11,  2.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|████▍            | 58/221 [00:26<01:13,  2.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|████▌            | 59/221 [00:26<01:13,  2.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|████▌            | 60/221 [00:27<01:12,  2.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|████▋            | 61/221 [00:28<01:13,  2.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|████▊            | 62/221 [00:28<01:13,  2.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████▊            | 63/221 [00:28<01:12,  2.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████▉            | 64/221 [00:29<01:11,  2.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|█████            | 65/221 [00:29<01:10,  2.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████            | 66/221 [00:29<01:10,  2.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▏           | 67/221 [00:30<01:09,  2.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|█████▏           | 68/221 [00:30<01:08,  2.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|█████▎           | 69/221 [00:30<01:08,  2.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|█████▍           | 70/221 [00:31<01:07,  2.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|█████▍           | 71/221 [00:31<01:06,  2.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|█████▌           | 72/221 [00:32<01:06,  2.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|█████▌           | 73/221 [00:32<01:05,  2.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|█████▋           | 74/221 [00:33<01:06,  2.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|█████▊           | 75/221 [00:34<01:06,  2.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|█████▊           | 76/221 [00:34<01:06,  2.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|█████▉           | 77/221 [00:35<01:05,  2.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████           | 78/221 [00:35<01:05,  2.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|██████           | 79/221 [00:36<01:05,  2.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|██████▏          | 80/221 [00:36<01:04,  2.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|██████▏          | 81/221 [00:37<01:04,  2.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|██████▎          | 82/221 [00:37<01:03,  2.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|██████▍          | 83/221 [00:37<01:03,  2.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|██████▍          | 84/221 [00:38<01:02,  2.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|██████▌          | 85/221 [00:39<01:02,  2.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|██████▌          | 86/221 [00:39<01:02,  2.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|██████▋          | 87/221 [00:40<01:02,  2.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|██████▊          | 88/221 [00:41<01:03,  2.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|██████▊          | 89/221 [00:42<01:02,  2.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|██████▉          | 90/221 [00:42<01:02,  2.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|███████          | 91/221 [00:43<01:01,  2.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|███████          | 92/221 [00:43<01:01,  2.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|███████▏         | 93/221 [00:43<01:00,  2.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▏         | 94/221 [00:44<00:59,  2.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▎         | 95/221 [00:44<00:59,  2.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▍         | 96/221 [00:45<00:59,  2.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|███████▍         | 97/221 [00:45<00:58,  2.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|███████▌         | 98/221 [00:46<00:58,  2.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|███████▌         | 99/221 [00:46<00:57,  2.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|███████▏        | 100/221 [00:46<00:56,  2.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|███████▎        | 101/221 [00:47<00:56,  2.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|███████▍        | 102/221 [00:48<00:56,  2.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|███████▍        | 103/221 [00:48<00:55,  2.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|███████▌        | 104/221 [00:49<00:55,  2.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|███████▌        | 105/221 [00:49<00:54,  2.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|███████▋        | 106/221 [00:50<00:54,  2.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|███████▋        | 107/221 [00:50<00:53,  2.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|███████▊        | 108/221 [00:51<00:53,  2.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|███████▉        | 109/221 [00:51<00:53,  2.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|███████▉        | 110/221 [00:52<00:52,  2.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|████████        | 111/221 [00:52<00:52,  2.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|████████        | 112/221 [00:53<00:52,  2.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|████████▏       | 113/221 [00:55<00:52,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|████████▎       | 114/221 [00:55<00:52,  2.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|████████▎       | 115/221 [00:55<00:51,  2.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|████████▍       | 116/221 [00:56<00:50,  2.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|████████▍       | 117/221 [00:56<00:50,  2.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|████████▌       | 118/221 [00:56<00:49,  2.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|████████▌       | 119/221 [00:57<00:49,  2.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|████████▋       | 120/221 [00:58<00:48,  2.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|████████▊       | 121/221 [00:58<00:48,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|████████▊       | 122/221 [00:59<00:48,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|████████▉       | 123/221 [00:59<00:47,  2.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|████████▉       | 124/221 [01:00<00:47,  2.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████       | 125/221 [01:01<00:46,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████       | 126/221 [01:01<00:46,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████▏      | 127/221 [01:02<00:46,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|█████████▎      | 128/221 [01:02<00:45,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|█████████▎      | 129/221 [01:03<00:45,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|█████████▍      | 130/221 [01:03<00:44,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|█████████▍      | 131/221 [01:04<00:44,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|█████████▌      | 132/221 [01:04<00:43,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|█████████▋      | 133/221 [01:04<00:42,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|█████████▋      | 134/221 [01:05<00:42,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|█████████▊      | 135/221 [01:05<00:41,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|█████████▊      | 136/221 [01:07<00:42,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|█████████▉      | 137/221 [01:08<00:41,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|█████████▉      | 138/221 [01:08<00:41,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|██████████      | 139/221 [01:08<00:40,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|██████████▏     | 140/221 [01:09<00:40,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|██████████▏     | 141/221 [01:09<00:39,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|██████████▎     | 142/221 [01:10<00:39,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|██████████▎     | 143/221 [01:10<00:38,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|██████████▍     | 144/221 [01:11<00:38,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|██████████▍     | 145/221 [01:11<00:37,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|██████████▌     | 146/221 [01:12<00:37,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████████▋     | 147/221 [01:12<00:36,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████████▋     | 148/221 [01:13<00:36,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████████▊     | 149/221 [01:13<00:35,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|██████████▊     | 150/221 [01:13<00:34,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|██████████▉     | 151/221 [01:14<00:34,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|███████████     | 152/221 [01:14<00:33,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|███████████     | 153/221 [01:15<00:33,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|███████████▏    | 154/221 [01:15<00:32,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|███████████▏    | 155/221 [01:15<00:32,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|███████████▎    | 156/221 [01:16<00:31,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|███████████▎    | 157/221 [01:17<00:31,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|███████████▍    | 158/221 [01:17<00:31,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|███████████▌    | 159/221 [01:18<00:30,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|███████████▌    | 160/221 [01:18<00:30,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|███████████▋    | 161/221 [01:19<00:29,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|███████████▋    | 162/221 [01:20<00:29,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|███████████▊    | 163/221 [01:21<00:29,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|███████████▊    | 164/221 [01:22<00:28,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|███████████▉    | 165/221 [01:22<00:28,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████    | 166/221 [01:22<00:27,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|████████████    | 167/221 [01:23<00:26,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|████████████▏   | 168/221 [01:23<00:26,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|████████████▏   | 169/221 [01:24<00:25,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|████████████▎   | 170/221 [01:24<00:25,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|████████████▍   | 171/221 [01:24<00:24,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|████████████▍   | 172/221 [01:25<00:24,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|████████████▌   | 173/221 [01:25<00:23,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|████████████▌   | 174/221 [01:26<00:23,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|████████████▋   | 175/221 [01:26<00:22,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████████▋   | 176/221 [01:26<00:22,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████████▊   | 177/221 [01:27<00:21,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|████████████▉   | 178/221 [01:27<00:21,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|████████████▉   | 179/221 [01:28<00:20,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|█████████████   | 180/221 [01:28<00:20,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|█████████████   | 181/221 [01:28<00:19,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|█████████████▏  | 182/221 [01:29<00:19,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|█████████████▏  | 183/221 [01:29<00:18,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|█████████████▎  | 184/221 [01:30<00:18,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|█████████████▍  | 185/221 [01:30<00:17,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|█████████████▍  | 186/221 [01:31<00:17,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|█████████████▌  | 187/221 [01:31<00:16,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|█████████████▌  | 188/221 [01:32<00:16,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|█████████████▋  | 189/221 [01:32<00:15,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|█████████████▊  | 190/221 [01:33<00:15,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|█████████████▊  | 191/221 [01:33<00:14,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|█████████████▉  | 192/221 [01:34<00:14,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|█████████████▉  | 193/221 [01:34<00:13,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|██████████████  | 194/221 [01:35<00:13,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|██████████████  | 195/221 [01:35<00:12,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|██████████████▏ | 196/221 [01:35<00:12,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|██████████████▎ | 197/221 [01:36<00:11,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|██████████████▎ | 198/221 [01:36<00:11,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|██████████████▍ | 199/221 [01:37<00:10,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|██████████████▍ | 200/221 [01:37<00:10,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|██████████████▌ | 201/221 [01:38<00:09,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|██████████████▌ | 202/221 [01:38<00:09,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|██████████████▋ | 203/221 [01:39<00:08,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|██████████████▊ | 204/221 [01:39<00:08,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|██████████████▊ | 205/221 [01:40<00:07,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|██████████████▉ | 206/221 [01:40<00:07,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|██████████████▉ | 207/221 [01:41<00:06,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|███████████████ | 208/221 [01:41<00:06,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|███████████████▏| 209/221 [01:42<00:05,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|███████████████▏| 210/221 [01:42<00:05,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|███████████████▎| 211/221 [01:43<00:04,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|███████████████▎| 212/221 [01:43<00:04,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|███████████████▍| 213/221 [01:43<00:03,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|███████████████▍| 214/221 [01:44<00:03,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|███████████████▌| 215/221 [01:45<00:02,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|███████████████▋| 216/221 [01:45<00:02,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|███████████████▋| 217/221 [01:45<00:01,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|███████████████▊| 218/221 [01:46<00:01,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|███████████████▊| 219/221 [01:47<00:00,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████▉| 220/221 [01:54<00:00,  1.93it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████| 221/221 [01:55<00:00,  1.92it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 266/266 [3:42:53<00:00,  0.02it/s, v_num=ym90, train/loss=0.867\u001b[A\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                       | 0/221 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                          | 0/221 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                  | 1/221 [00:00<01:11,  3.07it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏                 | 2/221 [00:00<01:00,  3.65it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏                 | 3/221 [00:00<00:54,  4.01it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎                 | 4/221 [00:00<00:52,  4.15it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▍                 | 5/221 [00:01<00:59,  3.65it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍                 | 6/221 [00:01<01:03,  3.39it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▌                 | 7/221 [00:02<01:08,  3.11it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▋                 | 8/221 [00:03<01:26,  2.47it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▋                 | 9/221 [00:03<01:23,  2.53it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▊                | 10/221 [00:04<01:26,  2.43it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▊                | 11/221 [00:04<01:25,  2.46it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                | 12/221 [00:04<01:25,  2.45it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|█                | 13/221 [00:05<01:24,  2.47it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|█                | 14/221 [00:06<01:34,  2.20it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|█▏               | 15/221 [00:06<01:31,  2.24it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|█▏               | 16/221 [00:07<01:30,  2.27it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▎               | 17/221 [00:07<01:29,  2.27it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▍               | 18/221 [00:08<01:32,  2.20it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▍               | 19/221 [00:08<01:30,  2.24it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▌               | 20/221 [00:08<01:28,  2.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▌               | 21/221 [00:09<01:27,  2.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▋               | 22/221 [00:09<01:26,  2.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊               | 23/221 [00:09<01:25,  2.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▊               | 24/221 [00:10<01:24,  2.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▉               | 25/221 [00:10<01:25,  2.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|██               | 26/221 [00:11<01:24,  2.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|██               | 27/221 [00:11<01:23,  2.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|██▏              | 28/221 [00:11<01:22,  2.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|██▏              | 29/221 [00:12<01:21,  2.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|██▎              | 30/221 [00:12<01:21,  2.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|██▍              | 31/221 [00:13<01:21,  2.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|██▍              | 32/221 [00:13<01:20,  2.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▌              | 33/221 [00:14<01:20,  2.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▌              | 34/221 [00:15<01:23,  2.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▋              | 35/221 [00:15<01:24,  2.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▊              | 36/221 [00:16<01:24,  2.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▊              | 37/221 [00:16<01:23,  2.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▉              | 38/221 [00:17<01:23,  2.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|███              | 39/221 [00:17<01:22,  2.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|███              | 40/221 [00:18<01:23,  2.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|███▏             | 41/221 [00:18<01:22,  2.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|███▏             | 42/221 [00:19<01:21,  2.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|███▎             | 43/221 [00:19<01:20,  2.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▍             | 44/221 [00:19<01:19,  2.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▍             | 45/221 [00:20<01:19,  2.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|███▌             | 46/221 [00:20<01:18,  2.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|███▌             | 47/221 [00:21<01:17,  2.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▋             | 48/221 [00:21<01:17,  2.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▊             | 49/221 [00:22<01:17,  2.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▊             | 50/221 [00:22<01:16,  2.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▉             | 51/221 [00:22<01:16,  2.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|████             | 52/221 [00:23<01:15,  2.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|████             | 53/221 [00:23<01:14,  2.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|████▏            | 54/221 [00:23<01:13,  2.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▏            | 55/221 [00:24<01:13,  2.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▎            | 56/221 [00:24<01:13,  2.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|████▍            | 57/221 [00:25<01:12,  2.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|████▍            | 58/221 [00:26<01:14,  2.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|████▌            | 59/221 [00:26<01:13,  2.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|████▌            | 60/221 [00:27<01:13,  2.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|████▋            | 61/221 [00:28<01:14,  2.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|████▊            | 62/221 [00:28<01:14,  2.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████▊            | 63/221 [00:29<01:13,  2.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████▉            | 64/221 [00:29<01:12,  2.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|█████            | 65/221 [00:29<01:11,  2.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████            | 66/221 [00:30<01:10,  2.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▏           | 67/221 [00:30<01:10,  2.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|█████▏           | 68/221 [00:30<01:09,  2.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|█████▎           | 69/221 [00:31<01:08,  2.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|█████▍           | 70/221 [00:31<01:08,  2.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|█████▍           | 71/221 [00:32<01:07,  2.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|█████▌           | 72/221 [00:32<01:06,  2.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|█████▌           | 73/221 [00:32<01:06,  2.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|█████▋           | 74/221 [00:33<01:07,  2.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|█████▊           | 75/221 [00:34<01:07,  2.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|█████▊           | 76/221 [00:35<01:06,  2.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|█████▉           | 77/221 [00:35<01:06,  2.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████           | 78/221 [00:36<01:06,  2.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|██████           | 79/221 [00:36<01:06,  2.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|██████▏          | 80/221 [00:37<01:05,  2.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|██████▏          | 81/221 [00:37<01:04,  2.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|██████▎          | 82/221 [00:38<01:04,  2.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|██████▍          | 83/221 [00:38<01:03,  2.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|██████▍          | 84/221 [00:38<01:03,  2.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|██████▌          | 85/221 [00:39<01:03,  2.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|██████▌          | 86/221 [00:40<01:03,  2.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|██████▋          | 87/221 [00:40<01:02,  2.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|██████▊          | 88/221 [00:42<01:03,  2.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|██████▊          | 89/221 [00:42<01:03,  2.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|██████▉          | 90/221 [00:43<01:02,  2.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|███████          | 91/221 [00:43<01:02,  2.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|███████          | 92/221 [00:43<01:01,  2.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|███████▏         | 93/221 [00:44<01:00,  2.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▏         | 94/221 [00:44<01:00,  2.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▎         | 95/221 [00:44<00:59,  2.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|███████▍         | 96/221 [00:45<00:59,  2.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|███████▍         | 97/221 [00:46<00:58,  2.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|███████▌         | 98/221 [00:46<00:58,  2.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|███████▌         | 99/221 [00:47<00:57,  2.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|███████▏        | 100/221 [00:47<00:57,  2.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|███████▎        | 101/221 [00:48<00:57,  2.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|███████▍        | 102/221 [00:48<00:56,  2.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|███████▍        | 103/221 [00:48<00:55,  2.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|███████▌        | 104/221 [00:49<00:55,  2.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|███████▌        | 105/221 [00:50<00:55,  2.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|███████▋        | 106/221 [00:50<00:54,  2.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|███████▋        | 107/221 [00:51<00:54,  2.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|███████▊        | 108/221 [00:51<00:54,  2.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|███████▉        | 109/221 [00:52<00:53,  2.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|███████▉        | 110/221 [00:52<00:53,  2.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|████████        | 111/221 [00:53<00:52,  2.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|████████        | 112/221 [00:54<00:52,  2.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|████████▏       | 113/221 [00:55<00:53,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|████████▎       | 114/221 [00:55<00:52,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|████████▎       | 115/221 [00:56<00:51,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|████████▍       | 116/221 [00:56<00:51,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|████████▍       | 117/221 [00:57<00:50,  2.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|████████▌       | 118/221 [00:57<00:50,  2.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|████████▌       | 119/221 [00:58<00:49,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|████████▋       | 120/221 [00:58<00:49,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|████████▊       | 121/221 [00:59<00:49,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|████████▊       | 122/221 [01:00<00:48,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|████████▉       | 123/221 [01:00<00:48,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|████████▉       | 124/221 [01:00<00:47,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████       | 125/221 [01:01<00:47,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████       | 126/221 [01:02<00:46,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|█████████▏      | 127/221 [01:03<00:46,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|█████████▎      | 128/221 [01:03<00:46,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|█████████▎      | 129/221 [01:04<00:45,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|█████████▍      | 130/221 [01:04<00:45,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|█████████▍      | 131/221 [01:05<00:44,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|█████████▌      | 132/221 [01:05<00:44,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|█████████▋      | 133/221 [01:05<00:43,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|█████████▋      | 134/221 [01:06<00:42,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|█████████▊      | 135/221 [01:06<00:42,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|█████████▊      | 136/221 [01:08<00:42,  1.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|█████████▉      | 137/221 [01:08<00:42,  1.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|█████████▉      | 138/221 [01:09<00:41,  1.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|██████████      | 139/221 [01:09<00:41,  1.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|██████████▏     | 140/221 [01:10<00:40,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|██████████▏     | 141/221 [01:10<00:39,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|██████████▎     | 142/221 [01:11<00:39,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|██████████▎     | 143/221 [01:11<00:38,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|██████████▍     | 144/221 [01:12<00:38,  1.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|██████████▍     | 145/221 [01:12<00:38,  1.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|██████████▌     | 146/221 [01:13<00:37,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████████▋     | 147/221 [01:13<00:37,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████████▋     | 148/221 [01:13<00:36,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|██████████▊     | 149/221 [01:14<00:35,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|██████████▊     | 150/221 [01:14<00:35,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|██████████▉     | 151/221 [01:15<00:34,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|███████████     | 152/221 [01:15<00:34,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|███████████     | 153/221 [01:15<00:33,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|███████████▏    | 154/221 [01:16<00:33,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|███████████▏    | 155/221 [01:16<00:32,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|███████████▎    | 156/221 [01:17<00:32,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|███████████▎    | 157/221 [01:18<00:31,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|███████████▍    | 158/221 [01:18<00:31,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|███████████▌    | 159/221 [01:19<00:30,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|███████████▌    | 160/221 [01:19<00:30,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|███████████▋    | 161/221 [01:19<00:29,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|███████████▋    | 162/221 [01:20<00:29,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|███████████▊    | 163/221 [01:22<00:29,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|███████████▊    | 164/221 [01:22<00:28,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|███████████▉    | 165/221 [01:23<00:28,  1.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████    | 166/221 [01:23<00:27,  1.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|████████████    | 167/221 [01:23<00:27,  1.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|████████████▏   | 168/221 [01:24<00:26,  1.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|████████████▏   | 169/221 [01:24<00:26,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|████████████▎   | 170/221 [01:24<00:25,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|████████████▍   | 171/221 [01:25<00:24,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|████████████▍   | 172/221 [01:25<00:24,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|████████████▌   | 173/221 [01:26<00:23,  2.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|████████████▌   | 174/221 [01:26<00:23,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|████████████▋   | 175/221 [01:26<00:22,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████████▋   | 176/221 [01:27<00:22,  2.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|████████████▊   | 177/221 [01:27<00:21,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|████████████▉   | 178/221 [01:28<00:21,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|████████████▉   | 179/221 [01:28<00:20,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|█████████████   | 180/221 [01:29<00:20,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|█████████████   | 181/221 [01:29<00:19,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|█████████████▏  | 182/221 [01:29<00:19,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|█████████████▏  | 183/221 [01:30<00:18,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|█████████████▎  | 184/221 [01:30<00:18,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|█████████████▍  | 185/221 [01:31<00:17,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|█████████████▍  | 186/221 [01:32<00:17,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|█████████████▌  | 187/221 [01:32<00:16,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|█████████████▌  | 188/221 [01:33<00:16,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|█████████████▋  | 189/221 [01:33<00:15,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|█████████████▊  | 190/221 [01:34<00:15,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|█████████████▊  | 191/221 [01:34<00:14,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|█████████████▉  | 192/221 [01:34<00:14,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|█████████████▉  | 193/221 [01:35<00:13,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|██████████████  | 194/221 [01:35<00:13,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|██████████████  | 195/221 [01:36<00:12,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|██████████████▏ | 196/221 [01:36<00:12,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|██████████████▎ | 197/221 [01:37<00:11,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|██████████████▎ | 198/221 [01:37<00:11,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|██████████████▍ | 199/221 [01:37<00:10,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|██████████████▍ | 200/221 [01:38<00:10,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|██████████████▌ | 201/221 [01:38<00:09,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|██████████████▌ | 202/221 [01:39<00:09,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|██████████████▋ | 203/221 [01:39<00:08,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|██████████████▊ | 204/221 [01:40<00:08,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|██████████████▊ | 205/221 [01:41<00:07,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|██████████████▉ | 206/221 [01:41<00:07,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|██████████████▉ | 207/221 [01:41<00:06,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|███████████████ | 208/221 [01:42<00:06,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|███████████████▏| 209/221 [01:42<00:05,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|███████████████▏| 210/221 [01:43<00:05,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|███████████████▎| 211/221 [01:43<00:04,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|███████████████▎| 212/221 [01:44<00:04,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|███████████████▍| 213/221 [01:44<00:03,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|███████████████▍| 214/221 [01:45<00:03,  2.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|███████████████▌| 215/221 [01:45<00:02,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|███████████████▋| 216/221 [01:46<00:02,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|███████████████▋| 217/221 [01:46<00:01,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|███████████████▊| 218/221 [01:47<00:01,  2.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|███████████████▊| 219/221 [01:48<00:00,  2.02it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████▉| 220/221 [01:54<00:00,  1.92it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████| 221/221 [01:56<00:00,  1.90it/s]\u001b[A\n",
      "Epoch 4:   0%| | 0/266 [00:00<?, ?it/s, v_num=ym90, train/loss=0.867, validation\u001b[A[E ProcessGroupNCCL.cpp:475] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=192776, OpType=ALLREDUCE, NumelIn=159440896, NumelOut=159440896, Timeout(ms)=1800000) ran for 1800103 milliseconds before timing out.\n",
      "[E ProcessGroupNCCL.cpp:475] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=192776, OpType=ALLREDUCE, NumelIn=159440896, NumelOut=159440896, Timeout(ms)=1800000) ran for 1800240 milliseconds before timing out.\n",
      "[E ProcessGroupNCCL.cpp:475] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=192776, OpType=ALLREDUCE, NumelIn=159440896, NumelOut=159440896, Timeout(ms)=1800000) ran for 1800396 milliseconds before timing out.\n",
      "[E ProcessGroupNCCL.cpp:475] [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=192776, OpType=ALLREDUCE, NumelIn=159440896, NumelOut=159440896, Timeout(ms)=1800000) ran for 1800421 milliseconds before timing out.\n",
      "[E ProcessGroupNCCL.cpp:475] [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=192776, OpType=ALLREDUCE, NumelIn=159440896, NumelOut=159440896, Timeout(ms)=1800000) ran for 1800549 milliseconds before timing out.\n",
      "[E ProcessGroupNCCL.cpp:475] [Rank 5] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=192776, OpType=ALLREDUCE, NumelIn=159440896, NumelOut=159440896, Timeout(ms)=1800000) ran for 1800580 milliseconds before timing out.\n",
      "[E ProcessGroupNCCL.cpp:475] [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=192776, OpType=ALLREDUCE, NumelIn=159440896, NumelOut=159440896, Timeout(ms)=1800000) ran for 1800685 milliseconds before timing out.\n",
      "[E ProcessGroupNCCL.cpp:475] [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=192776, OpType=ALLREDUCE, NumelIn=159440896, NumelOut=159440896, Timeout(ms)=1800000) ran for 1800930 milliseconds before timing out.\n"
     ]
    }
   ],
   "source": [
    "# Setup the checkpoint dir\n",
    "!cd \"{PROJECT_DIR}\" && mkdir -p \"./checkpoint/{CONFIG_FILE_NAME}/\"\n",
    "\n",
    "# Lets start the training\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    export RWKV_NO_CUDA=1 && \\\n",
    "    export RWKV_TORCH_COMPILE=0 && \\\n",
    "    export WANDB_MODE=\"{WANDB_MODE}\" && \\\n",
    "    python3 lightning_trainer.py fit \\\n",
    "        -c \"{NOTEBOOK_DIR}/{CONFIG_FILE_DIR}/{CONFIG_FILE_NAME}.yaml\" \\\n",
    "        --model.load_model=\"../model/{MODEL_NAME}\" \\\n",
    "        --data.skip_datapath_setup=True \\\n",
    "        --trainer.logger.init_args.name=\"{WANDB_PREFIX} - {CONFIG_FILE_NAME} (tctxlen={TRAINING_CTX_LEN}, {DEEPSPEED_STRAT})\" \\\n",
    "        --trainer.logger.init_args.project=\"{WANDB_PROJECT}\" \\\n",
    "        --trainer.strategy=\"{DEEPSPEED_STRAT}\" \\\n",
    "        --trainer.target_batch_size=1024 \\\n",
    "        --trainer.microbatch_size={MICROBATCH_SIZE} \\\n",
    "        --model.ctx_len={TRAINING_CTX_LEN} \\\n",
    "        --trainer.devices=\"{GPU_DEVICES}\"\n",
    "\n",
    "# For multi node training, you can add in the respective env variables\n",
    "# adjusted to your exact multi node use cases (reminder: adjust target_batch_size as well)\n",
    "# export MASTER_ADDR=10.130.0.24 && export MASTER_PORT=31856 && \\\n",
    "# export WORLD_SIZE=32 && export NODE_RANK=1 && \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-06 06:13:47,590] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/picocreator/RWKV-infctx-trainer/RWKV-v5/export_checkpoint.py\", line 651, in <module>\n",
      "    convert_zero_checkpoint_to_fp32_state_dict(args.checkpoint_dir, output_file, save_dtype=args.dtype)\n",
      "  File \"/workspace/picocreator/RWKV-infctx-trainer/RWKV-v5/export_checkpoint.py\", line 542, in convert_zero_checkpoint_to_fp32_state_dict\n",
      "    state_dict = get_fp32_state_dict_from_zero_checkpoint(checkpoint_dir, tag)\n",
      "  File \"/workspace/picocreator/RWKV-infctx-trainer/RWKV-v5/export_checkpoint.py\", line 516, in get_fp32_state_dict_from_zero_checkpoint\n",
      "    raise ValueError(f\"Unable to find 'latest' file at {latest_path}\")\n",
      "ValueError: Unable to find 'latest' file at ../checkpoint/Eagle-x-zMultipack-Instruct/last.ckpt/latest\n",
      "ls: cannot access '../model/Eagle-x-zMultipack-Instruct.pth': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Lets export the model from the checkpoint\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python export_checkpoint.py \"../checkpoint/{CONFIG_FILE_NAME}/last.ckpt\" \"../model/{CONFIG_FILE_NAME}.pth\"\n",
    "!cd \"{TRAINER_DIR}\" && ls -alh \"../model/{CONFIG_FILE_NAME}.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check (that the model actually output stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets do a quick dragon prompt validation\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python3 dragon_test.py \"../model/{CONFIG_FILE_NAME}.pth\" \"cuda bf16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
