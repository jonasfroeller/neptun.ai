{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RWKV Token Shift Experiment B\n",
    "This model is a custom model containing\n",
    "- 24 layers\n",
    "- 1024 embedding size\n",
    "\n",
    "See `./notes.md` for how the init model was initilaized.\n",
    "\n",
    "**Note:** This project assumes you have the rwkv-infctx conda env setup\n",
    "\n",
    "---\n",
    "\n",
    "```bash\n",
    "# ninja-build is required for the new trainer\n",
    "sudo apt-get install ninja-build\n",
    "\n",
    "# Update conda & its package listings\n",
    "conda update conda\n",
    "\n",
    "# Virtual env, with python 3.10\n",
    "# python 3.11 have issues with torch.compile / h100s\n",
    "# and if you want to use 3.11, you will need to do a nightly build install\n",
    "conda create -n rwkv-infctx python=3.11 pip\n",
    "conda activate rwkv-infctx\n",
    "\n",
    "# Install pytorch (>=2.0.1)\n",
    "conda install -y pytorch==2.0.1 torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia\n",
    "\n",
    "# Verify your pytorch version \n",
    "python -c \"import torch; print(torch.__version__)\"\n",
    "\n",
    "# We use python -m pip, instead of pip directly, as it resolve issues with venv not loading the right pip\n",
    "python -m pip install datasets transformers \n",
    "python -m pip install lightning==2.0.4 deepspeed==0.9.5\n",
    "python -m pip install ninja numexpr jsonargparse 'jsonargparse[signatures]'\n",
    "python -m pip install lm-dataformat ftfy sentencepiece tokenizers wandb\n",
    "```\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-07-20 06:07:53--  https://huggingface.co/picocreator/memory-size-experiment-for-rwkv/resolve/main/L24-D1024-init.pth\n",
      "Resolving huggingface.co (huggingface.co)... 143.204.55.121, 143.204.55.85, 143.204.55.75, ...\n",
      "Connecting to huggingface.co (huggingface.co)|143.204.55.121|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs.huggingface.co/repos/cb/ef/cbef09abb2634a3375b28868bffa285226dfeabedec89b28c2fb302221164d66/08948da228c8a8b7e5f77387e8f980dd20246fb375ee1c58a437b6bd075bf6e0?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27L24-D1024-init.pth%3B+filename%3D%22L24-D1024-init.pth%22%3B&Expires=1690092473&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5MDA5MjQ3M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9jYi9lZi9jYmVmMDlhYmIyNjM0YTMzNzViMjg4NjhiZmZhMjg1MjI2ZGZlYWJlZGVjODliMjhjMmZiMzAyMjIxMTY0ZDY2LzA4OTQ4ZGEyMjhjOGE4YjdlNWY3NzM4N2U4Zjk4MGRkMjAyNDZmYjM3NWVlMWM1OGE0MzdiNmJkMDc1YmY2ZTA%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=FGvM2ugyVKB0Zn5miTxIST0%7ENU70-gAfXaadjQjhkozwc4pOzYMKUm3-lMqWmIKe%7EBO3hzG7cvLxgcAewm3GXShnAJ4tMA-PuOc-K5jI0uJsRVcu4HcInHKf34H-N02SF3BBjakGzp5oymMn92rN0J2eLwwNjPU9fl6Uq1rgkJ-gLYQHcyVC84HMXAdaT2MR9swb3siZB535m4nZUFAyvN6dh%7E8o8Vfg4uTDCHAnU5rRlLIDn12P0-Gc-Znq0vAFtxYHjHmJwA0AYZCupmYZ7lPFth0ro2diT5SGLbTApReK4iq39Nw3M2eYIjrX5cxlVLNAgshfC93K423K1lcP0Q__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
      "--2023-07-20 06:07:53--  https://cdn-lfs.huggingface.co/repos/cb/ef/cbef09abb2634a3375b28868bffa285226dfeabedec89b28c2fb302221164d66/08948da228c8a8b7e5f77387e8f980dd20246fb375ee1c58a437b6bd075bf6e0?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27L24-D1024-init.pth%3B+filename%3D%22L24-D1024-init.pth%22%3B&Expires=1690092473&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5MDA5MjQ3M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9jYi9lZi9jYmVmMDlhYmIyNjM0YTMzNzViMjg4NjhiZmZhMjg1MjI2ZGZlYWJlZGVjODliMjhjMmZiMzAyMjIxMTY0ZDY2LzA4OTQ4ZGEyMjhjOGE4YjdlNWY3NzM4N2U4Zjk4MGRkMjAyNDZmYjM3NWVlMWM1OGE0MzdiNmJkMDc1YmY2ZTA%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=FGvM2ugyVKB0Zn5miTxIST0%7ENU70-gAfXaadjQjhkozwc4pOzYMKUm3-lMqWmIKe%7EBO3hzG7cvLxgcAewm3GXShnAJ4tMA-PuOc-K5jI0uJsRVcu4HcInHKf34H-N02SF3BBjakGzp5oymMn92rN0J2eLwwNjPU9fl6Uq1rgkJ-gLYQHcyVC84HMXAdaT2MR9swb3siZB535m4nZUFAyvN6dh%7E8o8Vfg4uTDCHAnU5rRlLIDn12P0-Gc-Znq0vAFtxYHjHmJwA0AYZCupmYZ7lPFth0ro2diT5SGLbTApReK4iq39Nw3M2eYIjrX5cxlVLNAgshfC93K423K1lcP0Q__&Key-Pair-Id=KVTP0A1DKRTAX\n",
      "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 54.230.111.125, 54.230.111.118, 54.230.111.126, ...\n",
      "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|54.230.111.125|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 860928133 (821M) [binary/octet-stream]\n",
      "Saving to: ‘L24-D1024-init.pth’\n",
      "\n",
      "L24-D1024-init.pth  100%[===================>] 821.04M  42.1MB/s    in 21s     \n",
      "\n",
      "2023-07-20 06:08:15 (38.7 MB/s) - ‘L24-D1024-init.pth’ saved [860928133/860928133]\n",
      "\n",
      "-rw-r--r-- 1 root root 822M Jul 20 04:34 ../../../../model/L24-D1024-init.pth\n"
     ]
    }
   ],
   "source": [
    "# First lets setup the various directories, and get the blank init model, these init model was generated\n",
    "# using the original RWKV-LM repo (as at this point of writing, this repo cannot init a model)\n",
    "# As such I have preinitialized these blank models and uploaded them to HF for convinence\n",
    "!mkdir -p ../../../../model/\n",
    "!mkdir -p ../../../../datapath/\n",
    "!mkdir -p ../../../../checkpoint/\n",
    "!cd ../../../../model/ && wget -nc https://huggingface.co/picocreator/memory-size-experiment-for-rwkv/resolve/main/L24-D1024-init.pth\n",
    "!ls -alh ../../../../model/L24-D1024-init.pth\n",
    "\n",
    "# The various other stages, if you want to skip stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEEPSPEED_STRAT: deepspeed_stage_1\n",
      "ENABLE_WANDB: True\n",
      "GPU_DEVICES: auto\n",
      "NOTEBOOK_DIR: /root/rwkv5x-tokenshift-exp-A/notebook/experiment/tokenshift-exp\n",
      "INFERENCE_DIR: /root/rwkv5x-tokenshift-exp-A/RWKV-v4wavenet\n",
      "TRAINER_DIR: /root/rwkv5x-tokenshift-exp-A/RWKV-v4wavenet\n",
      "PROJECT_DIR: /root/rwkv5x-tokenshift-exp-A\n"
     ]
    }
   ],
   "source": [
    "DEEPSPEED_STRAT=\"deepspeed_stage_1\"\n",
    "GPU_DEVICES=\"auto\"\n",
    "ENABLE_WANDB=True\n",
    "WANDB_PREFIX=\"TokenShift-Exp-B\"\n",
    "\n",
    "print(\"DEEPSPEED_STRAT:\", DEEPSPEED_STRAT)\n",
    "print(\"ENABLE_WANDB:\", ENABLE_WANDB)\n",
    "print(\"GPU_DEVICES:\", GPU_DEVICES)\n",
    "\n",
    "if ENABLE_WANDB:\n",
    "    WANDB_MODE=\"online\"\n",
    "else:\n",
    "    WANDB_MODE=\"disabled\"\n",
    "\n",
    "# Computing the notebook, and various paths\n",
    "import os\n",
    "NOTEBOOK_DIR=os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "PROJECT_DIR=os.path.abspath(os.path.join(NOTEBOOK_DIR, \"../../../../\"))\n",
    "TRAINER_DIR=os.path.abspath(os.path.join(PROJECT_DIR, \"./RWKV-v4wavenet/\"))\n",
    "INFERENCE_DIR=os.path.abspath(os.path.join(PROJECT_DIR, \"./RWKV-v4wavenet/\"))\n",
    "\n",
    "print(\"NOTEBOOK_DIR:\", NOTEBOOK_DIR)\n",
    "print(\"INFERENCE_DIR:\", INFERENCE_DIR)\n",
    "print(\"TRAINER_DIR:\", TRAINER_DIR)\n",
    "print(\"PROJECT_DIR:\", PROJECT_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 : Foundation model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/teven___parquet/teven--enwiki_100k-1359e81b212c2dd6/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 71.82it/s]\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Lets preload the requried dataset (enwiki_100k)\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python3 preload_datapath.py \"{NOTEBOOK_DIR}/TokenShift-B-enwiki.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "/usr/local/lib/python3.11/dist-packages/lightning/fabric/utilities/seed.py:39: UserWarning: No seed found, seed set to 2193157053\n",
      "  rank_zero_warn(f\"No seed found, seed set to {seed}\")\n",
      "Global seed set to 2193157053\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpicocreator\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./wandb/run-20230720_060952-on3b4cc0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mTokenShift-Exp-B - Enwiki Foundation (ctx=4096, deepspeed_stage_1)\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/picocreator/RWKV-5X-Experiments\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/picocreator/RWKV-5X-Experiments/runs/on3b4cc0\u001b[0m\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py311_cu118/wkv_4096_bf16/build.ninja...\n",
      "Building extension module wkv_4096_bf16...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/3] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=wkv_4096_bf16 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.11/dist-packages/torch/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.11/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -t 4 -std=c++17 -res-usage --maxrregcount 60 --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DTmax=4096 -c /root/rwkv5x-tokenshift-exp-A/RWKV-v4wavenet/cuda/wkv_cuda_bf16.cu -o wkv_cuda_bf16.cuda.o \n",
      "ptxas info    : 1 bytes gmem\n",
      "ptxas info    : Compiling entry function '_Z15kernel_backwardiiiPKfPKN3c108BFloat16ES4_S4_S0_S4_S0_PS2_S5_S5_S5_Pf' for 'sm_86'\n",
      "ptxas info    : Function properties for _Z15kernel_backwardiiiPKfPKN3c108BFloat16ES4_S4_S0_S4_S0_PS2_S5_S5_S5_Pf\n",
      "    49152 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 56 registers, 464 bytes cmem[0], 8 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function '_Z14kernel_forwardiiiPKfPKN3c108BFloat16ES4_S4_S0_PS2_Pf' for 'sm_86'\n",
      "ptxas info    : Function properties for _Z14kernel_forwardiiiPKfPKN3c108BFloat16ES4_S4_S0_PS2_Pf\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 40 registers, 424 bytes cmem[0]\n",
      "[2/3] c++ -MMD -MF wkv_op_bf16.o.d -DTORCH_EXTENSION_NAME=wkv_4096_bf16 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.11/dist-packages/torch/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.11/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -std=c++17 -O3 -DTmax=4096 -c /root/rwkv5x-tokenshift-exp-A/RWKV-v4wavenet/cuda/wkv_op_bf16.cpp -o wkv_op_bf16.o \n",
      "[3/3] c++ wkv_op_bf16.o wkv_cuda_bf16.cuda.o -shared -L/usr/local/lib/python3.11/dist-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o wkv_4096_bf16.so\n",
      "Loading extension module wkv_4096_bf16...\n",
      "/usr/local/lib/python3.11/dist-packages/lightning/fabric/connector.py:562: UserWarning: bf16 is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "\n",
      "[RWKV.Trainer] Applying 'target_batch_size' with the following:\n",
      "   - target_batch_size:       32\n",
      "   - num_nodes:               1\n",
      "   - num_devices:             8\n",
      "   - accumulate_grad_batches: 4\n",
      "   - effective_batch_size:    32\n",
      "\n",
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/teven___parquet/teven--enwiki_100k-1359e81b212c2dd6/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 66.36it/s]\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/teven___parquet/teven--enwiki_100k-1359e81b212c2dd6/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7/cache-1ae92a8fcbab5f66_*_of_00064.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/teven___parquet/teven--enwiki_100k-1359e81b212c2dd6/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7/cache-67576cf8a6607f3d_*_of_00064.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/teven___parquet/teven--enwiki_100k-1359e81b212c2dd6/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7/cache-f69b6b1c107274f3_*_of_00064.arrow\n",
      "Saving the dataset (0/5 shards):   0%|         | 0/81487 [00:00<?, ? examples/s]Setting ds_accelerator to cuda (auto detect)\n",
      "Saving the dataset (0/5 shards):   5%| | 4000/81487 [00:00<00:03, 25420.45 exampSetting ds_accelerator to cuda (auto detect)\n",
      "Setting ds_accelerator to cuda (auto detect)\n",
      "Setting ds_accelerator to cuda (auto detect)\n",
      "Setting ds_accelerator to cuda (auto detect)\n",
      "Setting ds_accelerator to cuda (auto detect)\n",
      "Saving the dataset (0/5 shards):  10%| | 8000/81487 [00:00<00:02, 30144.83 exampSetting ds_accelerator to cuda (auto detect)\n",
      "Saving the dataset (0/5 shards):  20%|▏| 16298/81487 [00:00<00:01, 35723.56 exam[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "Saving the dataset (1/5 shards):  20%|▏| 16298/81487 [00:00<00:01, 35723.56 exam[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "Saving the dataset (1/5 shards):  40%|▍| 32298/81487 [00:01<00:01, 32903.47 exam[rank: 7] Global seed set to 2193157053\n",
      "Saving the dataset (2/5 shards):  40%|▍| 32596/81487 [00:01<00:01, 32903.47 exam[rank: 5] Global seed set to 2193157053\n",
      "[rank: 4] Global seed set to 2193157053\n",
      "[rank: 3] Global seed set to 2193157053\n",
      "[rank: 1] Global seed set to 2193157053\n",
      "[rank: 2] Global seed set to 2193157053\n",
      "Saving the dataset (2/5 shards):  46%|▍| 37596/81487 [00:01<00:01, 27631.74 exam[rank: 6] Global seed set to 2193157053\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Saving the dataset (2/5 shards):  54%|▌| 43596/81487 [00:01<00:01, 31344.96 examDetected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py311_cu118/wkv_4096_bf16/build.ninja...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Saving the dataset (2/5 shards):  60%|▌| 48893/81487 [00:01<00:00, 33996.83 examBuilding extension module wkv_4096_bf16...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "ninja: no work to do.\n",
      "Loading extension module wkv_4096_bf16...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py311_cu118/wkv_4096_bf16/build.ninja...\n",
      "Saving the dataset (3/5 shards):  60%|▌| 48893/81487 [00:01<00:00, 33996.83 examBuilding extension module wkv_4096_bf16...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module wkv_4096_bf16...\n",
      "Loading extension module wkv_4096_bf16...\n",
      "Loading extension module wkv_4096_bf16...\n",
      "Loading extension module wkv_4096_bf16...\n",
      "Loading extension module wkv_4096_bf16...\n",
      "Loading extension module wkv_4096_bf16...\n",
      "[rank: 0] Global seed set to 2193157053                                         \n",
      "initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/8\n",
      "[2023-07-20 06:10:18,933] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[rank: 7] Global seed set to 2193157053\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 7, MEMBER: 8/8\n",
      "[2023-07-20 06:10:21,384] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[rank: 6] Global seed set to 2193157053\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 6, MEMBER: 7/8\n",
      "[2023-07-20 06:10:21,519] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[rank: 5] Global seed set to 2193157053\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 5, MEMBER: 6/8\n",
      "[2023-07-20 06:10:21,604] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[rank: 3] Global seed set to 2193157053\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/8\n",
      "[2023-07-20 06:10:22,480] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[rank: 2] Global seed set to 2193157053\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/8\n",
      "[2023-07-20 06:10:23,002] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[rank: 4] Global seed set to 2193157053\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 4, MEMBER: 5/8\n",
      "[2023-07-20 06:10:23,032] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[rank: 1] Global seed set to 2193157053\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/8\n",
      "[2023-07-20 06:10:23,044] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "Enabling DeepSpeed BF16.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "[RWKV.model] Configuring optimizer with\n",
      "    - lr_init:  6.000e-04 (0.0006)\n",
      "    - lr_final: 4.000e-04 (0.0004)\n",
      "\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py311_cu118/fused_adam/build.ninja...\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.06504440307617188 seconds\n",
      "Loading extension module fused_adam...\n",
      "Loading extension module fused_adam...\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.1014864444732666 seconds\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.1011812686920166 seconds\n",
      "Loading extension module fused_adam...\n",
      "Loading extension module fused_adam...\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.10170388221740723 seconds\n",
      "Time to load fused_adam op: 0.10152983665466309 seconds\n",
      "Time to load fused_adam op: 0.10182499885559082 seconds\n",
      "Time to load fused_adam op: 0.10183286666870117 seconds\n",
      "Time to load fused_adam op: 0.1018378734588623 seconds\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py311_cu118/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.06592941284179688 seconds\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.10177922248840332 seconds\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.10176801681518555 seconds\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.10179877281188965 seconds\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.10165095329284668 seconds\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.10133767127990723 seconds\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.10180878639221191 seconds\n",
      "Time to load utils op: 0.10169720649719238 seconds\n",
      "Rank: 6 partition count [8, 8, 8] and sizes[(53793536, False), (3072, False), (3072, False)] \n",
      "Rank: 7 partition count [8, 8, 8] and sizes[(53793536, False), (3072, False), (3072, False)] \n",
      "Rank: 0 partition count [8, 8, 8] and sizes[(53793536, False), (3072, False), (3072, False)] \n",
      "Rank: 5 partition count [8, 8, 8] and sizes[(53793536, False), (3072, False), (3072, False)] \n",
      "Rank: 1 partition count [8, 8, 8] and sizes[(53793536, False), (3072, False), (3072, False)] \n",
      "Rank: 2 partition count [8, 8, 8] and sizes[(53793536, False), (3072, False), (3072, False)] \n",
      "Rank: 4 partition count [8, 8, 8] and sizes[(53793536, False), (3072, False), (3072, False)] \n",
      "Rank: 3 partition count [8, 8, 8] and sizes[(53793536, False), (3072, False), (3072, False)] \n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.00026345252990722656 seconds\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0002694129943847656 seconds\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0002033710479736328 seconds\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.00028061866760253906 seconds\n",
      "Time to load utils op: 0.0002651214599609375 seconds\n",
      "Time to load utils op: 0.00030994415283203125 seconds\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.00025463104248046875 seconds\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0005412101745605469 seconds\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | emb    | Embedding  | 51.5 M\n",
      "1 | blocks | ModuleList | 327 M \n",
      "2 | ln_out | LayerNorm  | 2.0 K \n",
      "3 | head   | Linear     | 51.5 M\n",
      "--------------------------------------\n",
      "430 M     Trainable params\n",
      "0         Non-trainable params\n",
      "430 M     Total params\n",
      "1,721.590 Total estimated model params size (MB)\n",
      "Epoch 0:  10%| | 1000/10186 [10:40<1:38:01,  1.56it/s, v_num=4cc0, train/loss=4./usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Epoch 0: 100%|█| 10186/10186 [1:48:21<00:00,  1.57it/s, v_num=4cc0, train/loss=3\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/52 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/52 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎                  | 1/52 [00:00<00:10,  5.00it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▋                  | 2/52 [00:00<00:08,  5.56it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|█                  | 3/52 [00:00<00:08,  5.78it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▍                 | 4/52 [00:00<00:08,  5.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                 | 5/52 [00:00<00:07,  5.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|██▏                | 6/52 [00:00<00:07,  6.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|██▌                | 7/52 [00:01<00:07,  6.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▉                | 8/52 [00:01<00:07,  6.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|███▎               | 9/52 [00:01<00:07,  6.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|███▍              | 10/52 [00:01<00:06,  6.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|███▊              | 11/52 [00:01<00:06,  6.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|████▏             | 12/52 [00:01<00:06,  6.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▌             | 13/52 [00:02<00:06,  6.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|████▊             | 14/52 [00:02<00:06,  6.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|█████▏            | 15/52 [00:02<00:05,  6.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|█████▌            | 16/52 [00:02<00:05,  6.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|█████▉            | 17/52 [00:02<00:05,  6.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▏           | 18/52 [00:02<00:05,  6.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|██████▌           | 19/52 [00:03<00:05,  6.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|██████▉           | 20/52 [00:03<00:05,  6.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▎          | 21/52 [00:03<00:05,  6.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|███████▌          | 22/52 [00:03<00:04,  6.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|███████▉          | 23/52 [00:03<00:04,  6.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|████████▎         | 24/52 [00:03<00:04,  6.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|████████▋         | 25/52 [00:04<00:04,  6.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 26/52 [00:04<00:04,  6.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|█████████▎        | 27/52 [00:04<00:04,  6.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|█████████▋        | 28/52 [00:04<00:03,  6.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|██████████        | 29/52 [00:04<00:03,  6.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|██████████▍       | 30/52 [00:04<00:03,  6.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▋       | 31/52 [00:04<00:03,  6.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|███████████       | 32/52 [00:05<00:03,  6.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|███████████▍      | 33/52 [00:05<00:03,  6.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▊      | 34/52 [00:05<00:02,  6.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████████      | 35/52 [00:05<00:02,  6.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████████▍     | 36/52 [00:05<00:02,  6.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|████████████▊     | 37/52 [00:05<00:02,  6.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████████▏    | 38/52 [00:06<00:02,  6.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 39/52 [00:06<00:02,  6.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|█████████████▊    | 40/52 [00:06<00:01,  6.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████████▏   | 41/52 [00:06<00:01,  6.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████████▌   | 42/52 [00:06<00:01,  6.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████████▉   | 43/52 [00:06<00:01,  6.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▏  | 44/52 [00:07<00:01,  6.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████████▌  | 45/52 [00:07<00:01,  6.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████████▉  | 46/52 [00:07<00:00,  6.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▎ | 47/52 [00:07<00:00,  6.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|████████████████▌ | 48/52 [00:07<00:00,  6.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████████▉ | 49/52 [00:07<00:00,  6.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|█████████████████▎| 50/52 [00:08<00:00,  6.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|█████████████████▋| 51/52 [00:08<00:00,  6.24it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 10186/10186 [1:48:35<00:00,  1.56it/s, v_num=4cc0, train/loss=3\u001b[A\n",
      "Epoch 0: 100%|█| 10186/10186 [1:48:35<00:00,  1.56it/s, v_num=4cc0, train/loss=3\u001b[A`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Epoch 0: 100%|█| 10186/10186 [1:48:38<00:00,  1.56it/s, v_num=4cc0, train/loss=3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              batchidx ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 epoch ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           global_rank ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          real_ctx_len ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               substep ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/loss █▆▅▅▅▃▂▄▃▄▃▃▃▃▂▂▂▂▂▂▂▂▃▂▃▃▂▃▃▂▂▄▂▂▂▂▂▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   trainer/global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: trainer/learning_rate ███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation/loss ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              batchidx 51\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 epoch 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           global_rank 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          real_ctx_len 4095\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               substep 408\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/loss 3.4375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   trainer/global_step 2546\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: trainer/learning_rate 0.0004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation/loss 3.35599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mTokenShift-Exp-B - Enwiki Foundation (ctx=4096, deepspeed_stage_1)\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/picocreator/RWKV-5X-Experiments/runs/on3b4cc0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230720_060952-on3b4cc0/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Start the foundation model training\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    export WANDB_MODE=\"{WANDB_MODE}\" && \\\n",
    "    python lightning_trainer.py fit \\\n",
    "        -c \"{NOTEBOOK_DIR}/TokenShift-B-enwiki.yaml\" \\\n",
    "        --trainer.logger.init_args.name=\"{WANDB_PREFIX} - Enwiki Foundation (ctx=4096, {DEEPSPEED_STRAT})\" \\\n",
    "        --trainer.strategy=\"{DEEPSPEED_STRAT}\" \\\n",
    "        --trainer.devices=\"{GPU_DEVICES}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ds_accelerator to cuda (auto detect)\n",
      "Processing zero checkpoint '../checkpoint/TokenShift-B-enwiki/last.ckpt/checkpoint'\n",
      "Detected checkpoint of type zero stage ZeroStageEnum.optimizer_states, world_size: 8\n",
      "Parsing checkpoint created by deepspeed==0.9.3\n",
      "Reconstructed fp32 state dict with 438 params 430397440 elements\n",
      "Saving fp32 state dict to ../model/TokenShift-B-Stage1.pth\n",
      "-rw-r--r-- 1 root root 1.7G Jul 20 07:59 ../model/TokenShift-B-Stage1.pth\n"
     ]
    }
   ],
   "source": [
    "# Lets export the model from the checkpoint\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python export_checkpoint.py \"../checkpoint/TokenShift-B-enwiki/last.ckpt\" \"../model/TokenShift-B-Stage1.pth\"\n",
    "!cd \"{TRAINER_DIR}\" && ls -alh \"../model/TokenShift-B-Stage1.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py311_cu118/wkv_1024_bf16/build.ninja...\n",
      "Building extension module wkv_1024_bf16...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module wkv_1024_bf16...\n",
      "--- DRAGON PROMPT ---\n",
      "In a shocking finding, scientist discovered a herd of dragons living in a remote, previously unexplored valley, in Tibet. Even more surprising to the researchers was the fact that the dragons spoke perfect Chinese.\n",
      "\n",
      "Lectures and signs\n",
      "\n",
      "It was widely known that the Tibetan tribes in the Tibetan Plateau were a part of the Tibetan people. The Tibetan homeland was said to have been in the Tibet region. Tibetan-speaking Tibetans were especially attracted to the Tibetan Plateau because of its ancient land and salt deposits. The Tibetan plateau was situated on the east bank of the river in the Tibetan Plateau. It was near the source of the Tibetans who brought in animals for irrigation. They practiced the Buddhist language, Buddhism and Sikhism. They also found stone and other minerals. The Tibetan language was spoken by the Tibetan Buddhist, Tibetan and Lautian peoples in the area. The Tibetan-Lautic peoples spoke the Tibetan language, and spoke the Tibetan language. Tibetan Buddhism was the primary language in Tibet.\n",
      "\n",
      "According to the Tibetan Chronicles, the Tibetan Plateau was inhabited by a total of about 10,000 inhabitants, about 80% of the Tibetan population. Tibetan"
     ]
    }
   ],
   "source": [
    "# # Lets do a quick dragon prompt validation\n",
    "!cd \"{INFERENCE_DIR}\" && python3 dragon_test.py ../model/TokenShift-B-Stage1.pth \"cuda fp32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py311_cu118/wkv_1024_bf16/build.ninja...\n",
      "Building extension module wkv_1024_bf16...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/3] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=wkv_1024_bf16 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.11/dist-packages/torch/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.11/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -t 4 -std=c++17 -res-usage --maxrregcount 60 --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DTmax=1024 -c /root/rwkv5x-tokenshift-exp-A/RWKV-v4wavenet/cuda/wkv_cuda_bf16.cu -o wkv_cuda_bf16.cuda.o \n",
      "ptxas info    : 1 bytes gmem\n",
      "ptxas info    : Compiling entry function '_Z15kernel_backwardiiiPKfPKN3c108BFloat16ES4_S4_S0_S4_S0_PS2_S5_S5_S5_Pf' for 'sm_86'\n",
      "ptxas info    : Function properties for _Z15kernel_backwardiiiPKfPKN3c108BFloat16ES4_S4_S0_S4_S0_PS2_S5_S5_S5_Pf\n",
      "    12288 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 56 registers, 464 bytes cmem[0], 8 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function '_Z14kernel_forwardiiiPKfPKN3c108BFloat16ES4_S4_S0_PS2_Pf' for 'sm_86'\n",
      "ptxas info    : Function properties for _Z14kernel_forwardiiiPKfPKN3c108BFloat16ES4_S4_S0_PS2_Pf\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 40 registers, 424 bytes cmem[0]\n",
      "[2/3] c++ -MMD -MF wkv_op_bf16.o.d -DTORCH_EXTENSION_NAME=wkv_1024_bf16 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.11/dist-packages/torch/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.11/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -std=c++17 -O3 -DTmax=1024 -c /root/rwkv5x-tokenshift-exp-A/RWKV-v4wavenet/cuda/wkv_op_bf16.cpp -o wkv_op_bf16.o \n",
      "[3/3] c++ wkv_op_bf16.o wkv_cuda_bf16.cuda.o -shared -L/usr/local/lib/python3.11/dist-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o wkv_1024_bf16.so\n",
      "Loading extension module wkv_1024_bf16...\n",
      "###\n",
      "### Model validation start ###\n",
      "###\n",
      "## Model validation for 5 tokens : 0.0% similarity, with 0 matched token, and 5 token mismatch\n",
      "## Model validation for 10 tokens : 0.0% similarity, with 0 matched token, and 10 token mismatch\n",
      "## Model validation for 15 tokens : 0.0% similarity, with 0 matched token, and 15 token mismatch\n",
      "## Model validation for 20 tokens : 5.0% similarity, with 1 matched token, and 19 token mismatch\n",
      "## Model validation for 25 tokens : 4.0% similarity, with 1 matched token, and 24 token mismatch\n",
      "## Model validation for 30 tokens : 0.0% similarity, with 0 matched token, and 30 token mismatch\n",
      "## Model validation for 35 tokens : 0.0% similarity, with 0 matched token, and 35 token mismatch\n",
      "## Model validation for 40 tokens : 0.0% similarity, with 0 matched token, and 40 token mismatch\n",
      "## Model validation for 45 tokens : 0.0% similarity, with 0 matched token, and 45 token mismatch\n",
      "## Model validation for 50 tokens : 0.0% similarity, with 0 matched token, and 50 token mismatch\n",
      "## Model validation for 55 tokens : 0.0% similarity, with 0 matched token, and 55 token mismatch\n",
      "## Model validation for 60 tokens : 0.0% similarity, with 0 matched token, and 60 token mismatch\n",
      "## Model validation for 65 tokens : 0.0% similarity, with 0 matched token, and 65 token mismatch\n",
      "## Model validation for 70 tokens : 0.0% similarity, with 0 matched token, and 70 token mismatch\n",
      "## Model validation for 75 tokens : 0.0% similarity, with 0 matched token, and 75 token mismatch\n",
      "## Model validation for 80 tokens : 0.0% similarity, with 0 matched token, and 80 token mismatch\n",
      "## Model validation for 85 tokens : 0.0% similarity, with 0 matched token, and 85 token mismatch\n",
      "## Model validation for 90 tokens : 1.1111111111111112% similarity, with 1 matched token, and 89 token mismatch\n",
      "## Model validation for 95 tokens : 1.0526315789473684% similarity, with 1 matched token, and 94 token mismatch\n",
      "## Model validation for 100 tokens : 1.0% similarity, with 1 matched token, and 99 token mismatch\n",
      "## Model validation for 105 tokens : 0.9523809523809524% similarity, with 1 matched token, and 104 token mismatch\n",
      "## Model validation for 110 tokens : 0.9090909090909091% similarity, with 1 matched token, and 109 token mismatch\n",
      "## Model validation for 115 tokens : 0.8695652173913043% similarity, with 1 matched token, and 114 token mismatch\n",
      "## Model validation for 120 tokens : 0.8333333333333334% similarity, with 1 matched token, and 119 token mismatch\n",
      "## Model validation for 125 tokens : 0.8% similarity, with 1 matched token, and 124 token mismatch\n",
      "## Model validation for 130 tokens : 0.7692307692307693% similarity, with 1 matched token, and 129 token mismatch\n",
      "## Model validation for 135 tokens : 0.7407407407407408% similarity, with 1 matched token, and 134 token mismatch\n",
      "## Model validation for 140 tokens : 0.7142857142857143% similarity, with 1 matched token, and 139 token mismatch\n",
      "## Model validation for 145 tokens : 0.6896551724137931% similarity, with 1 matched token, and 144 token mismatch\n",
      "## Model validation for 150 tokens : 0.6666666666666667% similarity, with 1 matched token, and 149 token mismatch\n",
      "## Model validation for 160 tokens : 0.625% similarity, with 1 matched token, and 159 token mismatch\n",
      "## Model validation for 170 tokens : 0.5882352941176471% similarity, with 1 matched token, and 169 token mismatch\n",
      "## Model validation for 180 tokens : 0.5555555555555556% similarity, with 1 matched token, and 179 token mismatch\n",
      "## Model validation for 190 tokens : 1.0526315789473684% similarity, with 2 matched token, and 188 token mismatch\n",
      "## Model validation for 200 tokens : 1.0% similarity, with 2 matched token, and 198 token mismatch\n",
      "## Model validation for 210 tokens : 0.9523809523809524% similarity, with 2 matched token, and 208 token mismatch\n",
      "## Model validation for 220 tokens : 0.9090909090909091% similarity, with 2 matched token, and 218 token mismatch\n",
      "## Model validation for 230 tokens : 0.8695652173913043% similarity, with 2 matched token, and 228 token mismatch\n",
      "## Model validation for 240 tokens : 0.8333333333333334% similarity, with 2 matched token, and 238 token mismatch\n",
      "## Model validation for 250 tokens : 0.8% similarity, with 2 matched token, and 248 token mismatch\n",
      "## Model validation for 260 tokens : 0.7692307692307693% similarity, with 2 matched token, and 258 token mismatch\n",
      "## Model validation for 270 tokens : 0.7407407407407408% similarity, with 2 matched token, and 268 token mismatch\n",
      "## Model validation for 280 tokens : 0.7142857142857143% similarity, with 2 matched token, and 278 token mismatch\n",
      "## Model validation for 290 tokens : 1.3793103448275863% similarity, with 4 matched token, and 286 token mismatch\n",
      "## Model validation for 300 tokens : 1.3333333333333335% similarity, with 4 matched token, and 296 token mismatch\n",
      "## Model validation for 325 tokens : 1.2307692307692308% similarity, with 4 matched token, and 321 token mismatch\n",
      "## Model validation for 350 tokens : 1.1428571428571428% similarity, with 4 matched token, and 346 token mismatch\n",
      "## Model validation for 375 tokens : 1.3333333333333335% similarity, with 5 matched token, and 370 token mismatch\n",
      "## Model validation for 400 tokens : 1.25% similarity, with 5 matched token, and 395 token mismatch\n",
      "## Model validation for 425 tokens : 1.1764705882352942% similarity, with 5 matched token, and 420 token mismatch\n",
      "## Model validation for 450 tokens : 1.1111111111111112% similarity, with 5 matched token, and 445 token mismatch\n",
      "## Model validation for 475 tokens : 1.0526315789473684% similarity, with 5 matched token, and 470 token mismatch\n",
      "## Model validation for 500 tokens : 1.2% similarity, with 6 matched token, and 494 token mismatch\n",
      "## Model validation for 525 tokens : 1.1428571428571428% similarity, with 6 matched token, and 519 token mismatch\n",
      "## Model validation for 550 tokens : 1.4545454545454546% similarity, with 8 matched token, and 542 token mismatch\n",
      "## Model validation for 575 tokens : 1.391304347826087% similarity, with 8 matched token, and 567 token mismatch\n",
      "## Model validation for 600 tokens : 1.3333333333333335% similarity, with 8 matched token, and 592 token mismatch\n",
      "## Model validation for 625 tokens : 1.44% similarity, with 9 matched token, and 616 token mismatch\n",
      "## Model validation for 650 tokens : 1.3846153846153846% similarity, with 9 matched token, and 641 token mismatch\n",
      "## Model validation for 675 tokens : 1.3333333333333335% similarity, with 9 matched token, and 666 token mismatch\n",
      "## Model validation for 700 tokens : 1.2857142857142856% similarity, with 9 matched token, and 691 token mismatch\n",
      "## Model validation for 750 tokens : 1.3333333333333335% similarity, with 10 matched token, and 740 token mismatch\n",
      "## Model validation for 800 tokens : 1.25% similarity, with 10 matched token, and 790 token mismatch\n",
      "## Model validation for 850 tokens : 1.2941176470588236% similarity, with 11 matched token, and 839 token mismatch\n",
      "## Model validation for 900 tokens : 1.2222222222222223% similarity, with 11 matched token, and 889 token mismatch\n",
      "## Model validation for 950 tokens : 1.263157894736842% similarity, with 12 matched token, and 938 token mismatch\n",
      "## Model validation for 1000 tokens : 1.4000000000000001% similarity, with 14 matched token, and 986 token mismatch\n"
     ]
    }
   ],
   "source": [
    "# Lets do a quick memory test\n",
    "# (We dun expect this to work, as we have not finetune for memory recall, but its a baseline)\n",
    "!python3 ../memory_script/eval_model_memory_guided.py \"{PROJECT_DIR}/model/TokenShift-B-Stage1.pth\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2 : Instruct Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/c-s-ale___parquet/c-s-ale--dolly-15k-instruction-alpaca-format-9dfbb23260d63d9d/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 679.24it/s]\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Lets preload the requried dataset\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python3 preload_datapath.py \"{NOTEBOOK_DIR}/TokenShift-B-instruct.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "/usr/local/lib/python3.11/dist-packages/lightning/fabric/utilities/seed.py:39: UserWarning: No seed found, seed set to 1409080610\n",
      "  rank_zero_warn(f\"No seed found, seed set to {seed}\")\n",
      "Global seed set to 1409080610\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpicocreator\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./wandb/run-20230720_092037-um10rveg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mTokenShift-Exp-B - Instruct (train-ctx=4096, deepspeed_stage_1)\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/picocreator/RWKV-5X-Experiments\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/picocreator/RWKV-5X-Experiments/runs/um10rveg\u001b[0m\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py311_cu118/wkv_4096_bf16/build.ninja...\n",
      "Building extension module wkv_4096_bf16...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module wkv_4096_bf16...\n",
      "/usr/local/lib/python3.11/dist-packages/lightning/fabric/connector.py:562: UserWarning: bf16 is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "\n",
      "[RWKV.Trainer] Applying 'target_batch_size' with the following:\n",
      "   - target_batch_size:       32\n",
      "   - num_nodes:               1\n",
      "   - num_devices:             8\n",
      "   - accumulate_grad_batches: 4\n",
      "   - effective_batch_size:    32\n",
      "\n",
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/c-s-ale___parquet/c-s-ale--dolly-15k-instruction-alpaca-format-9dfbb23260d63d9d/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 758.05it/s]\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/c-s-ale___parquet/c-s-ale--dolly-15k-instruction-alpaca-format-9dfbb23260d63d9d/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7/cache-497b18043dca9701_*_of_00064.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/c-s-ale___parquet/c-s-ale--dolly-15k-instruction-alpaca-format-9dfbb23260d63d9d/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7/cache-7e82136b48a2b575_*_of_00064.arrow\n",
      "[rank: 0] Global seed set to 1409080610                                         \n",
      "initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/8\n",
      "[2023-07-20 09:20:44,412] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "Setting ds_accelerator to cuda (auto detect)\n",
      "Setting ds_accelerator to cuda (auto detect)\n",
      "Setting ds_accelerator to cuda (auto detect)\n",
      "Setting ds_accelerator to cuda (auto detect)\n",
      "Setting ds_accelerator to cuda (auto detect)\n",
      "Setting ds_accelerator to cuda (auto detect)\n",
      "Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "[rank: 1] Global seed set to 1409080610\n",
      "[rank: 3] Global seed set to 1409080610\n",
      "[rank: 4] Global seed set to 1409080610\n",
      "[rank: 6] Global seed set to 1409080610\n",
      "[rank: 2] Global seed set to 1409080610\n",
      "[rank: 7] Global seed set to 1409080610\n",
      "[rank: 5] Global seed set to 1409080610\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py311_cu118/wkv_4096_bf16/build.ninja...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Building extension module wkv_4096_bf16...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "ninja: no work to do.\n",
      "Loading extension module wkv_4096_bf16...\n",
      "Loading extension module wkv_4096_bf16...\n",
      "Loading extension module wkv_4096_bf16...\n",
      "Loading extension module wkv_4096_bf16...\n",
      "Loading extension module wkv_4096_bf16...\n",
      "Loading extension module wkv_4096_bf16...\n",
      "Loading extension module wkv_4096_bf16...\n",
      "[rank: 3] Global seed set to 1409080610\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/8\n",
      "[2023-07-20 09:20:52,943] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[rank: 4] Global seed set to 1409080610\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 4, MEMBER: 5/8\n",
      "[2023-07-20 09:20:55,318] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[rank: 7] Global seed set to 1409080610\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 7, MEMBER: 8/8\n",
      "[2023-07-20 09:20:55,340] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[rank: 2] Global seed set to 1409080610\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/8\n",
      "[2023-07-20 09:20:55,355] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[rank: 5] Global seed set to 1409080610\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 5, MEMBER: 6/8\n",
      "[2023-07-20 09:20:55,358] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[rank: 1] Global seed set to 1409080610\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/8\n",
      "[2023-07-20 09:20:55,363] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[rank: 6] Global seed set to 1409080610\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 6, MEMBER: 7/8\n",
      "[2023-07-20 09:20:55,372] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "Enabling DeepSpeed BF16.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "[RWKV.model] Configuring optimizer with\n",
      "    - lr_init:  4.000e-04 (0.0004)\n",
      "    - lr_final: 3.000e-04 (0.0003)\n",
      "\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py311_cu118/fused_adam/build.ninja...\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.06619071960449219 seconds\n",
      "Loading extension module fused_adam...\n",
      "Loading extension module fused_adam...\n",
      "Loading extension module fused_adam...\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.1013798713684082 seconds\n",
      "Time to load fused_adam op: 0.10139107704162598 seconds\n",
      "Loading extension module fused_adam...\n",
      "Loading extension module fused_adam...\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.10144281387329102 seconds\n",
      "Time to load fused_adam op: 0.10145020484924316 seconds\n",
      "Time to load fused_adam op: 0.10167717933654785 seconds\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Time to load fused_adam op: 0.10181546211242676 seconds\n",
      "Time to load fused_adam op: 0.10180997848510742 seconds\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py311_cu118/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.06350517272949219 seconds\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.10223531723022461 seconds\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.10168051719665527 seconds\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.10193681716918945 seconds\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.10181450843811035 seconds\n",
      "Time to load utils op: 0.10188412666320801 seconds\n",
      "Time to load utils op: 0.10140156745910645 seconds\n",
      "Time to load utils op: 0.10142993927001953 seconds\n",
      "Rank: 0 partition count [8, 8, 8] and sizes[(53793536, False), (3072, False), (3072, False)] \n",
      "Rank: 4 partition count [8, 8, 8] and sizes[(53793536, False), (3072, False), (3072, False)] \n",
      "Rank: 2 partition count [8, 8, 8] and sizes[(53793536, False), (3072, False), (3072, False)] \n",
      "Rank: 6 partition count [8, 8, 8] and sizes[(53793536, False), (3072, False), (3072, False)] \n",
      "Rank: 1 partition count [8, 8, 8] and sizes[(53793536, False), (3072, False), (3072, False)] \n",
      "Rank: 5 partition count [8, 8, 8] and sizes[(53793536, False), (3072, False), (3072, False)] \n",
      "Rank: 3 partition count [8, 8, 8] and sizes[(53793536, False), (3072, False), (3072, False)] \n",
      "Rank: 7 partition count [8, 8, 8] and sizes[(53793536, False), (3072, False), (3072, False)] \n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.00026535987854003906 seconds\n",
      "Time to load utils op: 0.0002675056457519531 seconds\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.00026726722717285156 seconds\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0002651214599609375 seconds\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.00027179718017578125 seconds\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Time to load utils op: 0.0002624988555908203 seconds\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0002961158752441406 seconds\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.00048732757568359375 seconds\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | emb    | Embedding  | 51.5 M\n",
      "1 | blocks | ModuleList | 327 M \n",
      "2 | ln_out | LayerNorm  | 2.0 K \n",
      "3 | head   | Linear     | 51.5 M\n",
      "--------------------------------------\n",
      "430 M     Trainable params\n",
      "0         Non-trainable params\n",
      "430 M     Total params\n",
      "1,721.590 Total estimated model params size (MB)\n",
      "Epoch 0:  54%|▌| 1000/1867 [06:48<05:54,  2.45it/s, v_num=rveg, train/loss=2.520/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Epoch 0: 100%|█| 1867/1867 [12:21<00:00,  2.52it/s, v_num=rveg, train/loss=3.080\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▉                 | 1/10 [00:00<00:01,  4.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 2/10 [00:00<00:01,  5.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 3/10 [00:00<00:01,  5.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 4/10 [00:00<00:01,  5.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████▌         | 5/10 [00:00<00:00,  5.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████████▍       | 6/10 [00:01<00:00,  5.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████████▎     | 7/10 [00:01<00:00,  6.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|███████████████▏   | 8/10 [00:01<00:00,  6.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|█████████████████  | 9/10 [00:01<00:00,  6.10it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 1867/1867 [12:28<00:00,  2.49it/s, v_num=rveg, train/loss=3.080\u001b[A\n",
      "Epoch 0: 100%|█| 1867/1867 [12:28<00:00,  2.49it/s, v_num=rveg, train/loss=3.080\u001b[A`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Epoch 0: 100%|█| 1867/1867 [12:34<00:00,  2.48it/s, v_num=rveg, train/loss=3.080\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              batchidx ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 epoch ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           global_rank ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          real_ctx_len ▁▁▄▂▁▂▃▂▁█▁▃▁▄▂▂▁▁▃▄▁▃▂▅▄▂▁▅▃▅▁▂▃▁▄▃▃▅▂▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               substep ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/loss ▄▅▅▆▅▆▅▅▅▇▄▅▃▆▃█▄▆▄▆▇▄▃▂▆▅▆▅▅▆▅▆▇▆▅▁▃▄▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   trainer/global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: trainer/learning_rate ████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation/loss ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              batchidx 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 epoch 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           global_rank 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          real_ctx_len 213\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               substep 72\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/loss 2.42188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   trainer/global_step 466\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: trainer/learning_rate 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       validation/loss 3.11348\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mTokenShift-Exp-B - Instruct (train-ctx=4096, deepspeed_stage_1)\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/picocreator/RWKV-5X-Experiments/runs/um10rveg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230720_092037-um10rveg/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Start the instruct finetuning\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    export WANDB_MODE=\"{WANDB_MODE}\" && \\\n",
    "    python lightning_trainer.py fit \\\n",
    "        -c \"{NOTEBOOK_DIR}/TokenShift-B-instruct.yaml\" \\\n",
    "        --trainer.logger.init_args.name=\"{WANDB_PREFIX} - Instruct (train-ctx=4096, {DEEPSPEED_STRAT})\" \\\n",
    "        --trainer.strategy=\"{DEEPSPEED_STRAT}\" \\\n",
    "        --trainer.devices=\"{GPU_DEVICES}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ds_accelerator to cuda (auto detect)\n",
      "Processing zero checkpoint '../checkpoint/TokenShift-B-instruct/last.ckpt/checkpoint'\n",
      "Detected checkpoint of type zero stage ZeroStageEnum.optimizer_states, world_size: 8\n",
      "Parsing checkpoint created by deepspeed==0.9.3\n",
      "Reconstructed fp32 state dict with 438 params 430397440 elements\n",
      "Saving fp32 state dict to ../model/TokenShift-B-Stage2.pth\n",
      "-rw-r--r-- 1 root root 1.7G Jul 20 09:34 ../model/TokenShift-B-Stage2.pth\n"
     ]
    }
   ],
   "source": [
    "# Lets export the model from the checkpoint\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python export_checkpoint.py \"../checkpoint/TokenShift-B-instruct/last.ckpt\" \"../model/TokenShift-B-Stage2.pth\"\n",
    "!cd \"{TRAINER_DIR}\" && ls -alh \"../model/TokenShift-B-Stage2.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py311_cu118/wkv_1024_bf16/build.ninja...\n",
      "Building extension module wkv_1024_bf16...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module wkv_1024_bf16...\n",
      "--- DRAGON PROMPT ---\n",
      "In a shocking finding, scientist discovered a herd of dragons living in a remote, previously unexplored valley, in Tibet. Even more surprising to the researchers was the fact that the dragons spoke perfect Chinese. Soon after the discovery of the deer, a curious dune bug has been found, and the two Chinese dragons were invited to work at a zoo. The zoo was a big success in Taiwan, and was able to learn more about Tibetan. In the finals of the zoo, a small party of Nepalese fans was invited to a museum in the hall. In another mid-60s dune buggy was revived, and a power station was built in it. Also, the entire village was bought by a local politician. Soon after, the governor of Jakarta, Captain Heron, who had recently been in charge, was arrested by his Indian assistant, Mr. D. D. Wahoo.\n",
      "When he was traveling to the Tibetan Zoo, he had a high tide of excitement and excitement. A strong consideration was made by Mr. D. D. so he could find his way out of the park. The zoo manager, Mr. D. D. later received some good reviews"
     ]
    }
   ],
   "source": [
    "# Lets do a quick dragon prompt validation\n",
    "!cd \"{INFERENCE_DIR}\" && python3 dragon_test.py \"../model/TokenShift-B-Stage2.pth\" \"cuda fp32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py311_cu118/wkv_1024_bf16/build.ninja...\n",
      "Building extension module wkv_1024_bf16...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module wkv_1024_bf16...\n",
      "###\n",
      "### Model validation start ###\n",
      "###\n",
      "## Model validation for 5 tokens : 20.0% similarity, with 1 matched token, and 4 token mismatch\n",
      "## Model validation for 10 tokens : 10.0% similarity, with 1 matched token, and 9 token mismatch\n",
      "## Model validation for 15 tokens : 6.666666666666667% similarity, with 1 matched token, and 14 token mismatch\n",
      "## Model validation for 20 tokens : 5.0% similarity, with 1 matched token, and 19 token mismatch\n",
      "## Model validation for 25 tokens : 4.0% similarity, with 1 matched token, and 24 token mismatch\n",
      "## Model validation for 30 tokens : 3.3333333333333335% similarity, with 1 matched token, and 29 token mismatch\n",
      "## Model validation for 35 tokens : 2.857142857142857% similarity, with 1 matched token, and 34 token mismatch\n",
      "## Model validation for 40 tokens : 2.5% similarity, with 1 matched token, and 39 token mismatch\n",
      "## Model validation for 45 tokens : 2.2222222222222223% similarity, with 1 matched token, and 44 token mismatch\n",
      "## Model validation for 50 tokens : 2.0% similarity, with 1 matched token, and 49 token mismatch\n",
      "## Model validation for 55 tokens : 1.8181818181818181% similarity, with 1 matched token, and 54 token mismatch\n",
      "## Model validation for 60 tokens : 1.6666666666666667% similarity, with 1 matched token, and 59 token mismatch\n",
      "## Model validation for 65 tokens : 1.5384615384615385% similarity, with 1 matched token, and 64 token mismatch\n",
      "## Model validation for 70 tokens : 1.4285714285714286% similarity, with 1 matched token, and 69 token mismatch\n",
      "## Model validation for 75 tokens : 1.3333333333333335% similarity, with 1 matched token, and 74 token mismatch\n",
      "## Model validation for 80 tokens : 1.25% similarity, with 1 matched token, and 79 token mismatch\n",
      "## Model validation for 85 tokens : 1.1764705882352942% similarity, with 1 matched token, and 84 token mismatch\n",
      "## Model validation for 90 tokens : 2.2222222222222223% similarity, with 2 matched token, and 88 token mismatch\n",
      "## Model validation for 95 tokens : 1.0526315789473684% similarity, with 1 matched token, and 94 token mismatch\n",
      "## Model validation for 100 tokens : 1.0% similarity, with 1 matched token, and 99 token mismatch\n",
      "## Model validation for 105 tokens : 0.9523809523809524% similarity, with 1 matched token, and 104 token mismatch\n",
      "## Model validation for 110 tokens : 0.9090909090909091% similarity, with 1 matched token, and 109 token mismatch\n",
      "## Model validation for 115 tokens : 0.8695652173913043% similarity, with 1 matched token, and 114 token mismatch\n",
      "## Model validation for 120 tokens : 0.8333333333333334% similarity, with 1 matched token, and 119 token mismatch\n",
      "## Model validation for 125 tokens : 0.8% similarity, with 1 matched token, and 124 token mismatch\n",
      "## Model validation for 130 tokens : 0.7692307692307693% similarity, with 1 matched token, and 129 token mismatch\n",
      "## Model validation for 135 tokens : 0.7407407407407408% similarity, with 1 matched token, and 134 token mismatch\n",
      "## Model validation for 140 tokens : 0.7142857142857143% similarity, with 1 matched token, and 139 token mismatch\n",
      "## Model validation for 145 tokens : 0.6896551724137931% similarity, with 1 matched token, and 144 token mismatch\n",
      "## Model validation for 150 tokens : 0.6666666666666667% similarity, with 1 matched token, and 149 token mismatch\n",
      "## Model validation for 160 tokens : 0.625% similarity, with 1 matched token, and 159 token mismatch\n",
      "## Model validation for 170 tokens : 0.5882352941176471% similarity, with 1 matched token, and 169 token mismatch\n",
      "## Model validation for 180 tokens : 0.5555555555555556% similarity, with 1 matched token, and 179 token mismatch\n",
      "## Model validation for 190 tokens : 1.0526315789473684% similarity, with 2 matched token, and 188 token mismatch\n",
      "## Model validation for 200 tokens : 1.0% similarity, with 2 matched token, and 198 token mismatch\n",
      "## Model validation for 210 tokens : 0.9523809523809524% similarity, with 2 matched token, and 208 token mismatch\n",
      "## Model validation for 220 tokens : 0.9090909090909091% similarity, with 2 matched token, and 218 token mismatch\n",
      "## Model validation for 230 tokens : 0.8695652173913043% similarity, with 2 matched token, and 228 token mismatch\n",
      "## Model validation for 240 tokens : 0.8333333333333334% similarity, with 2 matched token, and 238 token mismatch\n",
      "## Model validation for 250 tokens : 0.8% similarity, with 2 matched token, and 248 token mismatch\n",
      "## Model validation for 260 tokens : 0.7692307692307693% similarity, with 2 matched token, and 258 token mismatch\n",
      "## Model validation for 270 tokens : 0.7407407407407408% similarity, with 2 matched token, and 268 token mismatch\n",
      "## Model validation for 280 tokens : 0.7142857142857143% similarity, with 2 matched token, and 278 token mismatch\n",
      "## Model validation for 290 tokens : 1.0344827586206897% similarity, with 3 matched token, and 287 token mismatch\n",
      "## Model validation for 300 tokens : 1.0% similarity, with 3 matched token, and 297 token mismatch\n",
      "## Model validation for 325 tokens : 0.9230769230769231% similarity, with 3 matched token, and 322 token mismatch\n",
      "## Model validation for 350 tokens : 0.8571428571428572% similarity, with 3 matched token, and 347 token mismatch\n",
      "## Model validation for 375 tokens : 1.0666666666666667% similarity, with 4 matched token, and 371 token mismatch\n",
      "## Model validation for 400 tokens : 1.0% similarity, with 4 matched token, and 396 token mismatch\n",
      "## Model validation for 425 tokens : 0.9411764705882352% similarity, with 4 matched token, and 421 token mismatch\n",
      "## Model validation for 450 tokens : 0.8888888888888888% similarity, with 4 matched token, and 446 token mismatch\n",
      "## Model validation for 475 tokens : 0.8421052631578947% similarity, with 4 matched token, and 471 token mismatch\n",
      "## Model validation for 500 tokens : 1.0% similarity, with 5 matched token, and 495 token mismatch\n",
      "## Model validation for 525 tokens : 0.9523809523809524% similarity, with 5 matched token, and 520 token mismatch\n",
      "## Model validation for 550 tokens : 1.090909090909091% similarity, with 6 matched token, and 544 token mismatch\n",
      "## Model validation for 575 tokens : 1.0434782608695654% similarity, with 6 matched token, and 569 token mismatch\n",
      "## Model validation for 600 tokens : 1.0% similarity, with 6 matched token, and 594 token mismatch\n",
      "## Model validation for 625 tokens : 1.1199999999999999% similarity, with 7 matched token, and 618 token mismatch\n",
      "## Model validation for 650 tokens : 1.0769230769230769% similarity, with 7 matched token, and 643 token mismatch\n",
      "## Model validation for 675 tokens : 1.037037037037037% similarity, with 7 matched token, and 668 token mismatch\n",
      "## Model validation for 700 tokens : 1.0% similarity, with 7 matched token, and 693 token mismatch\n",
      "## Model validation for 750 tokens : 1.0666666666666667% similarity, with 8 matched token, and 742 token mismatch\n",
      "## Model validation for 800 tokens : 1.0% similarity, with 8 matched token, and 792 token mismatch\n",
      "## Model validation for 850 tokens : 1.1764705882352942% similarity, with 10 matched token, and 840 token mismatch\n",
      "## Model validation for 900 tokens : 1.1111111111111112% similarity, with 10 matched token, and 890 token mismatch\n",
      "## Model validation for 950 tokens : 1.1578947368421053% similarity, with 11 matched token, and 939 token mismatch\n",
      "## Model validation for 1000 tokens : 1.2% similarity, with 12 matched token, and 988 token mismatch\n"
     ]
    }
   ],
   "source": [
    "# Lets do a quick memory test\n",
    "# (We dun expect this to work, as we have not finetune for memory recall, but its a baseline)\n",
    "!python3 ../memory_script/eval_model_memory_guided.py \"{PROJECT_DIR}/model/TokenShift-B-Stage2.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
