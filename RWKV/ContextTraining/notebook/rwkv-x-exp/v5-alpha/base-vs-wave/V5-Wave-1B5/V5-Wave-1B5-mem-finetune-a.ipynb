{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RWKV v5 Wavenet - memory finetune\n",
    "\n",
    "This continues off from `./V5-Wave-1B5-basemodel.ipynb` to perform the full memory finetune & testing process\n",
    "\n",
    "This is done generally across the following stages\n",
    "- Tune 1: Low ctx size (512), Training with only the input masked. This does very limited memory training, and is used primarily to train the instructions.\n",
    "- Tune 2: Low ctx size (512), Training with instruction & input masked. This forces the actual memory training on the output tokens.\n",
    "- Tune 3: Mid ctx size (1024), scaled up\n",
    "- Tune 4: Mid ctx size (2048), scaled up\n",
    "- Tune 5: Mid ctx size (4096), scaled up\n",
    "- Tune 6: Large ctx size (8192), scaled up\n",
    "\n",
    "In all cases, the input tokens is always masked. And we intentionally use the limited word set for memory training, which matches the same wordset used in the original memory evaluation of raven pretrained models. This is intentional to serve as both consistent comparision between experiments, and resonable training time.\n",
    "\n",
    "One of the issue faced previously with an excessive large word set, is that the model would be required to see the \"new words\" atleast a few time before being able to train the memory process. This drastically slowed down the process as the large word list meant the model was constantly spending time learning new words (instead of memory training).\n",
    "\n",
    "If we want to increase the number / type of words the model can handle for memory training, that can be done later as a stages memory tune if needed. But this exceeds the current requirements for the memory experiment process.\n",
    "\n",
    "> This project assumes you have the rwkv-infctx conda env setup, and you are executing in that environment - see the main README.md for the conda env setup steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Download the pretrained model\n",
    "(if you want to skip the the basemodel train + instruct tune)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init required dirs\n",
    "!mkdir -p ../../../../model/\n",
    "!mkdir -p ../../../../datapath/\n",
    "!mkdir -p ../../../../checkpoint/\n",
    "\n",
    "# Download the Stage2.pth file\n",
    "!cd ../../../../model/ && wget -nc https://huggingface.co/picocreator/memory-size-experiment-for-rwkv/resolve/main/V5x-16k/V5-Wave-1B5-Stage2.pth\n",
    "!ls -alh ../../../../model/V5-Wave-1B5-Stage2.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure your environment settings\n",
    "(!Important: you will need to rerun the below cell, if you restart your kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEEPSPEED_STRAT=\"deepspeed_stage_1\"\n",
    "GPU_DEVICES=\"auto\"\n",
    "ENABLE_WANDB=True\n",
    "WANDB_PREFIX=\"V5-Wave-1B5\"\n",
    "\n",
    "# WAVENET LAYERS settings\n",
    "RWKV_WAVENET_LAYERS=13\n",
    "\n",
    "print(\"DEEPSPEED_STRAT:\", DEEPSPEED_STRAT)\n",
    "print(\"ENABLE_WANDB:\", ENABLE_WANDB)\n",
    "print(\"GPU_DEVICES:\", GPU_DEVICES)\n",
    "print(\"RWKV_WAVENET_LAYERS:\", RWKV_WAVENET_LAYERS)\n",
    "\n",
    "if ENABLE_WANDB:\n",
    "    WANDB_MODE=\"online\"\n",
    "else:\n",
    "    WANDB_MODE=\"disabled\"\n",
    "\n",
    "# Computing the notebook, and various paths\n",
    "import os\n",
    "NOTEBOOK_DIR=os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "PROJECT_DIR=os.path.abspath(os.path.join(NOTEBOOK_DIR, \"../../../../\"))\n",
    "TRAINER_DIR=os.path.abspath(os.path.join(PROJECT_DIR, \"./RWKV-v5/\"))\n",
    "INFERENCE_DIR=os.path.abspath(os.path.join(PROJECT_DIR, \"./RWKV-v5/\"))\n",
    "\n",
    "print(\"NOTEBOOK_DIR:\", NOTEBOOK_DIR)\n",
    "print(\"INFERENCE_DIR:\", INFERENCE_DIR)\n",
    "print(\"TRAINER_DIR:\", TRAINER_DIR)\n",
    "print(\"PROJECT_DIR:\", PROJECT_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune 1 : Simple Memory instruct finetuning\n",
    "\n",
    "- Tune 1: Low ctx size (512), Training with only the input masked. This does very limited memory training, and is used primarily to train the instruction set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "########################################\n",
    "# Generate the required jsonl dataset\n",
    "########################################\n",
    "\n",
    "# Reset the dataset dir\n",
    "mkdir -p ../dataset\n",
    "rm -rf ../dataset/*.jsonl\n",
    "\n",
    "# Generate the various datasets\n",
    "echo \"## Generating word reptition dataset ##\"\n",
    "\n",
    "# Lets generate for ctx len <= 512\n",
    "python ../memory_script/gen_limited_segmented_jsonl.py ../dataset/word-2-count.jsonl  2  1000 &\n",
    "for i in {5..250..5} \n",
    "do\n",
    "    python ../memory_script/gen_limited_segmented_jsonl.py ../dataset/gen-word-$i-count.jsonl $i 1000 & \n",
    "done\n",
    "\n",
    "wait\n",
    "echo \"## Done ##\"\n",
    "\n",
    "ls -alh ../dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the checkpoint\n",
    "!cd \"{TRAINER_DIR}\" && mkdir -p \"../checkpoint/V5-Wave-1B5-mem-instruct/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the finetune model training\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    export WANDB_MODE=\"{WANDB_MODE}\" && \\\n",
    "    export RWKV_WAVENET_LAYERS=\"{RWKV_WAVENET_LAYERS}\" && \\\n",
    "    python lightning_trainer.py fit \\\n",
    "        -c \"{NOTEBOOK_DIR}/V5-Wave-1B5-mem-instruct.yaml\" \\\n",
    "        --trainer.logger.init_args.name=\"{WANDB_PREFIX} - Mem-Instruct (bs=256, train-ctx=512, {DEEPSPEED_STRAT})\" \\\n",
    "        --trainer.strategy=\"{DEEPSPEED_STRAT}\" \\\n",
    "        --trainer.devices=\"{GPU_DEVICES}\"  \\\n",
    "        --model.ctx_len=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets export the model from the checkpoint\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python export_checkpoint.py \\\n",
    "        \"../checkpoint/V5-Base-mem-instruct/last.ckpt\" \\\n",
    "        \"../model/V5-Wave-1B5-Tune-1.pth\"\n",
    "!cd \"{TRAINER_DIR}\" && ls -alh \"../model/V5-Wave-1B5-Tune-1.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lets do a memory eval\n",
    "# #\n",
    "# # Note that the expected performance \"is not that great\", as the model seems to be only loosely\n",
    "# # learning the memorization task, and the instruction propmt. And is seem to be acting more\n",
    "# # like an RNG based on the instruct. (Instead of the actual memorization task)\n",
    "# !python3 ../memory_script/eval_memory_guided.py \"{PROJECT_DIR}/model/V5-Wave-1B5-Tune1.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune 2 : Low ctx size (512), memory training\n",
    "\n",
    "- Tune 2: Low ctx size (512), Training with instruction & input masked. This forces the actual memory training on the output tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "########################################\n",
    "# Generate the required jsonl dataset\n",
    "########################################\n",
    "\n",
    "# Reset the dataset dir\n",
    "mkdir -p ../dataset\n",
    "rm -rf ../dataset/*.jsonl\n",
    "\n",
    "# Generate the various datasets\n",
    "echo \"## Generating word reptition dataset ##\"\n",
    "\n",
    "#\n",
    "# We switch over to fully masked instruct+input, to properly learn the memorization task\n",
    "#\n",
    "python ../memory_script/gen_limited_prompt_completion_jsonl.py ../dataset/word-2-count.jsonl  2  1000 &\n",
    "for i in {5..250..5} \n",
    "do\n",
    "    python ../memory_script/gen_limited_prompt_completion_jsonl.py ../dataset/gen-word-$i-count.jsonl $i 1000 & \n",
    "    python ../memory_script/shuffle_limited_prompt_completion_jsonl.py ../dataset/shuffle-word-$i-count.jsonl $i 100 &\n",
    "done\n",
    "\n",
    "wait\n",
    "echo \"## Done ##\"\n",
    "\n",
    "ls -alh ../dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the checkpoint directory exists, and reset it\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    mkdir -p \"../checkpoint/V5-Wave-1B5-mem-ctx-512/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the finetune model training\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    export WANDB_MODE=\"{WANDB_MODE}\" && \\\n",
    "    export RWKV_WAVENET_LAYERS=\"{RWKV_WAVENET_LAYERS}\" && \\\n",
    "    python lightning_trainer.py fit \\\n",
    "        -c \"{NOTEBOOK_DIR}/V5-Wave-1B5-mem-template.yaml\" \\\n",
    "        --trainer.logger.init_args.name=\"{WANDB_PREFIX} - Mem-Tune Ctx-512 (bs=256, train-ctx=512, {DEEPSPEED_STRAT})\" \\\n",
    "        --trainer.strategy=\"{DEEPSPEED_STRAT}\" \\\n",
    "        --trainer.devices=\"{GPU_DEVICES}\"  \\\n",
    "        --model.lr_init=5e-4 \\\n",
    "        --model.lr_final=4e-4 \\\n",
    "        --data.max_token_size=512 \\\n",
    "        --model.ctx_len=512 \\\n",
    "        --model.bptt_learning_range=1 \\\n",
    "        --model.load_model=\"../V5-Wave-1B5-Tune-1.pth\" \\\n",
    "        --callback[0].dirpath=\"../checkpoint/V5-Wave-1B5-mem-ctx-512/\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets export the model from the checkpoint\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python export_checkpoint.py \\\n",
    "        \"../checkpoint/V5-Wave-1B5-mem-ctx-512/last.ckpt\" \\\n",
    "        \"../model/V5-Wave-1B5-Tune-ctx512.pth\"\n",
    "!cd \"{TRAINER_DIR}\" && ls -alh ../model/V5-Wave-1B5-Tune2.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lets do a memory eval \n",
    "# #\n",
    "# # While not at its full potential, its memory ability should start emerging\n",
    "# #\n",
    "# !python3 ../memory_script/eval_memory_guided.py \"{PROJECT_DIR}/model/V5-Wave-1B5-Tune2.pth\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
