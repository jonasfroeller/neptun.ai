{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RWKV v5\n",
    "\n",
    "Simple memory training for a small model\n",
    "\n",
    "**Note:** This project assumes you have the rwkv-infctx conda env setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First lets setup the various directories, and init the model\n",
    "!ls ../../../../../\n",
    "!mkdir -p ../../../../../models/\n",
    "!mkdir -p ../../../../../datapath/\n",
    "!mkdir -p ../../../../../checkpoint/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional dependencies for eval stuff\n",
    "!pip3 install -q aiocsv aiofiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEEPSPEED_STRAT: deepspeed_stage_1\n",
      "ENABLE_WANDB: True\n",
      "GPU_DEVICES: auto\n",
      "DIR_NAME: infctx-math-and-name\n",
      "NOTEBOOK_DIR: /data/chris/rwkv-fork/RWKV-infctx-trainer/notebook/experiment/infctx-math-and-name\n",
      "INFERENCE_DIR: /data/chris/rwkv-fork/RWKV-infctx-trainer/RWKV-v5\n",
      "TRAINER_DIR: /data/chris/rwkv-fork/RWKV-infctx-trainer/RWKV-v5\n",
      "PROJECT_DIR: /data/chris/rwkv-fork/RWKV-infctx-trainer\n"
     ]
    }
   ],
   "source": [
    "DEEPSPEED_STRAT=\"deepspeed_stage_1\"\n",
    "GPU_DEVICES=\"auto\"\n",
    "ENABLE_WANDB=True\n",
    "\n",
    "# Layer count and embed dim to start with\n",
    "LAYER_COUNT=6\n",
    "EMBED_DIM=2048\n",
    "\n",
    "EMBED_SCALE=0.1\n",
    "EMBED_SCALE_LABEL=str(EMBED_SCALE).replace(\".\", \"_\")\n",
    "\n",
    "WANDB_PREFIX=f\"v5r3-L{LAYER_COUNT}-D{EMBED_DIM}-E{EMBED_SCALE}\"\n",
    "FILENAME_PREFIX=f\"v5r3-L{LAYER_COUNT}-D{EMBED_DIM}-E{EMBED_SCALE_LABEL}\"\n",
    "\n",
    "print(\"DEEPSPEED_STRAT:\", DEEPSPEED_STRAT)\n",
    "print(\"ENABLE_WANDB:\", ENABLE_WANDB)\n",
    "print(\"GPU_DEVICES:\", GPU_DEVICES)\n",
    "\n",
    "if ENABLE_WANDB:\n",
    "    WANDB_MODE=\"online\"\n",
    "else:\n",
    "    WANDB_MODE=\"disabled\"\n",
    "\n",
    "# Computing the notebook, and various paths\n",
    "import os\n",
    "NOTEBOOK_DIR=os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "CONFIG_DIR=os.path.abspath(os.path.join(NOTEBOOK_DIR, \"./\"))\n",
    "PROJECT_DIR=os.path.abspath(os.path.join(CONFIG_DIR, \"../../../\"))\n",
    "TRAINER_DIR=os.path.abspath(os.path.join(PROJECT_DIR, \"./RWKV-v5/\"))\n",
    "INFERENCE_DIR=os.path.abspath(os.path.join(PROJECT_DIR, \"./RWKV-v5/\"))\n",
    "\n",
    "# Get the notebook dir name\n",
    "DIR_NAME=os.path.basename(NOTEBOOK_DIR)\n",
    "\n",
    "# Log names and dir\n",
    "print(\"DIR_NAME:\", DIR_NAME)\n",
    "print(\"NOTEBOOK_DIR:\", NOTEBOOK_DIR)\n",
    "print(\"INFERENCE_DIR:\", INFERENCE_DIR)\n",
    "print(\"TRAINER_DIR:\", TRAINER_DIR)\n",
    "print(\"PROJECT_DIR:\", PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-09-16 17:59:33--  https://huggingface.co/rwkv-x-dev/rwkv-x-playground/resolve/main/experiment/rwkv-x-exp/v5-r3-memory/L6-D2048-E1e-1-ctx4k/v5r3-L6-D2048-E0_1-enwiki-instruct.pth\n",
      "Resolving huggingface.co (huggingface.co)... 108.138.246.71, 108.138.246.85, 108.138.246.67, ...\n",
      "Connecting to huggingface.co (huggingface.co)|108.138.246.71|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs.huggingface.co/repos/2e/f7/2ef78555202aa92abdbdf476ce3d0fd5a8b15f7245edf0b80d4d30572355f30d/0a83bdbbf6d686bfa77529fc9bbde3a91fc8d182e1dc33ce8d18f2a0abbe2576?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27v5r3-L6-D2048-E0_1-enwiki-instruct.pth%3B+filename%3D%22v5r3-L6-D2048-E0_1-enwiki-instruct.pth%22%3B&Expires=1695171573&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NTE3MTU3M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy8yZS9mNy8yZWY3ODU1NTIwMmFhOTJhYmRiZGY0NzZjZTNkMGZkNWE4YjE1ZjcyNDVlZGYwYjgwZDRkMzA1NzIzNTVmMzBkLzBhODNiZGJiZjZkNjg2YmZhNzc1MjlmYzliYmRlM2E5MWZjOGQxODJlMWRjMzNjZThkMThmMmEwYWJiZTI1NzY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=ydnz2x0eG1WBO%7ExW3sMHufYylEixqjKRuxzCPaRc0AdGMtoIsv1lnJ7DcU0TtY4RQZpUxvmtEdE43zQtOf7Bf80qf8U0mLnGOaEZLxuCrKXodOa8c8N58xr5c0Kl4XofpifWg%7EUeO2xAKAY%7EYgSyzqJDVFEzcifyu69bLA1fgZJwM7V5w4YmkJ2mmLp7wxicVMOh9y8f7evkoG9wNd2NjuTje7VhbptyFYio4KoMLfUwwXO1C5nXTYawFEIXN%7EZNpNgGeDZkPGt0RwdL4OVav8m6if%7E89QbaEnWlPjWulswil%7EkjC5893H9l7FvRJYVQAmuXOeeFcJoG64xDSjluGQ__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
      "--2023-09-16 17:59:33--  https://cdn-lfs.huggingface.co/repos/2e/f7/2ef78555202aa92abdbdf476ce3d0fd5a8b15f7245edf0b80d4d30572355f30d/0a83bdbbf6d686bfa77529fc9bbde3a91fc8d182e1dc33ce8d18f2a0abbe2576?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27v5r3-L6-D2048-E0_1-enwiki-instruct.pth%3B+filename%3D%22v5r3-L6-D2048-E0_1-enwiki-instruct.pth%22%3B&Expires=1695171573&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NTE3MTU3M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy8yZS9mNy8yZWY3ODU1NTIwMmFhOTJhYmRiZGY0NzZjZTNkMGZkNWE4YjE1ZjcyNDVlZGYwYjgwZDRkMzA1NzIzNTVmMzBkLzBhODNiZGJiZjZkNjg2YmZhNzc1MjlmYzliYmRlM2E5MWZjOGQxODJlMWRjMzNjZThkMThmMmEwYWJiZTI1NzY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=ydnz2x0eG1WBO%7ExW3sMHufYylEixqjKRuxzCPaRc0AdGMtoIsv1lnJ7DcU0TtY4RQZpUxvmtEdE43zQtOf7Bf80qf8U0mLnGOaEZLxuCrKXodOa8c8N58xr5c0Kl4XofpifWg%7EUeO2xAKAY%7EYgSyzqJDVFEzcifyu69bLA1fgZJwM7V5w4YmkJ2mmLp7wxicVMOh9y8f7evkoG9wNd2NjuTje7VhbptyFYio4KoMLfUwwXO1C5nXTYawFEIXN%7EZNpNgGeDZkPGt0RwdL4OVav8m6if%7E89QbaEnWlPjWulswil%7EkjC5893H9l7FvRJYVQAmuXOeeFcJoG64xDSjluGQ__&Key-Pair-Id=KVTP0A1DKRTAX\n",
      "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.238.192.105, 18.238.192.34, 18.238.192.50, ...\n",
      "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.238.192.105|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1066537777 (1017M) [binary/octet-stream]\n",
      "Saving to: ‘v5r3-L6-D2048-E0_1-enwiki-instruct.pth’\n",
      "\n",
      "v5r3-L6-D2048-E0_1- 100%[===================>]   1017M   112MB/s    in 9.1s    \n",
      "\n",
      "2023-09-16 17:59:42 (112 MB/s) - ‘v5r3-L6-D2048-E0_1-enwiki-instruct.pth’ saved [1066537777/1066537777]\n",
      "\n",
      "total 703M\n",
      "drwx------  2 christopherchou u-christopherchou     3 Sep 16 17:59 .\n",
      "drwx------ 17 christopherchou u-christopherchou    21 Sep 16 17:59 ..\n",
      "-rw-------  1 christopherchou u-christopherchou 1018M Sep 13 13:28 v5r3-L6-D2048-E0_1-enwiki-instruct.pth\n"
     ]
    }
   ],
   "source": [
    "# Download the model directly (stop gap till HF sync issues is resolved)\n",
    "!cd \"{TRAINER_DIR}\" && cd \"../models/\" && \\\n",
    "    wget -nc \"https://huggingface.co/rwkv-x-dev/rwkv-x-playground/resolve/main/experiment/rwkv-x-exp/v5-r3-memory/L6-D2048-E1e-1-ctx4k/v5r3-L6-D2048-E0_1-enwiki-instruct.pth\"\n",
    "\n",
    "!cd \"{TRAINER_DIR}\" && cd \"../models/\" && \\\n",
    "    ls -alh ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune 2 : Context size (1024) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Generating math and name dataset ##\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Done ##\n",
      "total 25M\n",
      "drwx------  2 christopherchou u-christopherchou   3 Sep 16 17:59 .\n",
      "drwx------ 13 christopherchou u-christopherchou  14 Sep 16 17:59 ..\n",
      "-rw-------  1 christopherchou u-christopherchou 55M Sep 16 17:59 questions_numbers.jsonl\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "########################################\n",
    "# Generate the required jsonl dataset\n",
    "########################################\n",
    "\n",
    "# Go to config dir\n",
    "cd \"../\"\n",
    "\n",
    "# Reset the dataset dir\n",
    "mkdir -p ../dataset\n",
    "rm -rf ../dataset/*.jsonl\n",
    "\n",
    "# Generate the various datasets\n",
    "echo \"## Generating math and name dataset ##\"\n",
    "\n",
    "#\n",
    "# We reduce the training set for lower word count - and shift the focus upwards\n",
    "#\n",
    "# do\n",
    "python3 infctx-math-and-name/generate_math_and_name_dataset.py --out-file ../dataset/questions_numbers.jsonl --max-numbers 1024 --num-samples 10000\n",
    "# done\n",
    "\n",
    "wait\n",
    "echo \"## Done ##\"\n",
    "\n",
    "ls -alh ../dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu117'\n",
      "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/data/chris/rwkv-fork/RWKV-infctx-trainer/RWKV-v5/\u001b[0m\u001b[1;33mlightning_trainer.py\u001b[0m:\u001b[94m278\u001b[0m   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m275 \u001b[0m\u001b[2m│   \u001b[0m)                                                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m276 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m277 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m278 \u001b[2m│   \u001b[0mcli_main()                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m279 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/data/chris/rwkv-fork/RWKV-infctx-trainer/RWKV-v5/\u001b[0m\u001b[1;33mlightning_trainer.py\u001b[0m:\u001b[94m253\u001b[0m   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m in \u001b[92mcli_main\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m250 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96msrc\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mtrainer\u001b[0m \u001b[94mimport\u001b[0m RWKVLightningTrainer                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m251 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m252 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcli_main\u001b[0m():                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m253 \u001b[2m│   \u001b[0mLightningCLI(                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m254 \u001b[0m\u001b[2m│   │   \u001b[0mRWKV, RWKVDataModule,                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m255 \u001b[0m\u001b[2m│   │   \u001b[0msave_config_kwargs={\u001b[33m\"\u001b[0m\u001b[33moverwrite\u001b[0m\u001b[33m\"\u001b[0m: \u001b[94mTrue\u001b[0m},                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m256 \u001b[0m\u001b[2m│   │   \u001b[0mtrainer_class=RWKVLightningTrainer,                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/data/chris/anaconda3/envs/fastchat-env/lib/python3.8/site-packages/lightnin\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mg/pytorch/\u001b[0m\u001b[1;33mcli.py\u001b[0m:\u001b[94m348\u001b[0m in \u001b[92m__init__\u001b[0m                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m345 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.subclass_mode_data = (datamodule_class \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m) \u001b[95mor\u001b[0m subcla \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m346 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m347 \u001b[0m\u001b[2m│   │   \u001b[0mmain_kwargs, subparser_kwargs = \u001b[96mself\u001b[0m._setup_parser_kwargs(\u001b[96mself\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m348 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.setup_parser(run, main_kwargs, subparser_kwargs)          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m349 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.parse_arguments(\u001b[96mself\u001b[0m.parser, args)                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m350 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m351 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.subcommand = \u001b[96mself\u001b[0m.config[\u001b[33m\"\u001b[0m\u001b[33msubcommand\u001b[0m\u001b[33m\"\u001b[0m] \u001b[94mif\u001b[0m run \u001b[94melse\u001b[0m \u001b[94mNone\u001b[0m   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/data/chris/anaconda3/envs/fastchat-env/lib/python3.8/site-packages/lightnin\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mg/pytorch/\u001b[0m\u001b[1;33mcli.py\u001b[0m:\u001b[94m380\u001b[0m in \u001b[92msetup_parser\u001b[0m                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m377 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m, add_subcommands: \u001b[96mbool\u001b[0m, main_kwargs: Dict[\u001b[96mstr\u001b[0m, Any], subp \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m378 \u001b[0m\u001b[2m│   \u001b[0m) -> \u001b[94mNone\u001b[0m:                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m379 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Initialize and setup the parser, subcommands, and arguments\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m380 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.parser = \u001b[96mself\u001b[0m.init_parser(**main_kwargs)                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m381 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m add_subcommands:                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m382 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._subcommand_method_arguments: Dict[\u001b[96mstr\u001b[0m, List[\u001b[96mstr\u001b[0m]] =  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m383 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._add_subcommands(\u001b[96mself\u001b[0m.parser, **subparser_kwargs)     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/data/chris/anaconda3/envs/fastchat-env/lib/python3.8/site-packages/lightnin\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mg/pytorch/\u001b[0m\u001b[1;33mcli.py\u001b[0m:\u001b[94m370\u001b[0m in \u001b[92minit_parser\u001b[0m                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m367 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92minit_parser\u001b[0m(\u001b[96mself\u001b[0m, **kwargs: Any) -> LightningArgumentParser:   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m368 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Method that instantiates the argument parser.\"\"\"\u001b[0m            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m369 \u001b[0m\u001b[2m│   │   \u001b[0mkwargs.setdefault(\u001b[33m\"\u001b[0m\u001b[33mdump_header\u001b[0m\u001b[33m\"\u001b[0m, [\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mlightning.pytorch==\u001b[0m\u001b[33m{\u001b[0mpl.__v \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m370 \u001b[2m│   │   \u001b[0mparser = LightningArgumentParser(**kwargs)                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m371 \u001b[0m\u001b[2m│   │   \u001b[0mparser.add_argument(                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m372 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m-c\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33m--config\u001b[0m\u001b[33m\"\u001b[0m, action=ActionConfigFile, help=\u001b[33m\"\u001b[0m\u001b[33mPath to a\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m373 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/data/chris/anaconda3/envs/fastchat-env/lib/python3.8/site-packages/lightnin\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mg/pytorch/\u001b[0m\u001b[1;33mcli.py\u001b[0m:\u001b[94m94\u001b[0m in \u001b[92m__init__\u001b[0m                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 91 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 92 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 93 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m _JSONARGPARSE_SIGNATURES_AVAILABLE:                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 94 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mModuleNotFoundError\u001b[0m(                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 95 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0m_JSONARGPARSE_SIGNATURES_AVAILABLE\u001b[33m}\u001b[0m\u001b[33m. Try `pip insta\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 96 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 97 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96msuper\u001b[0m().\u001b[92m__init__\u001b[0m(*args, description=description, env_prefix=en \u001b[31m│\u001b[0m\n",
      "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[1;91mModuleNotFoundError: \u001b[0mDistributionNotFound: The \n",
      "\u001b[32m'jsonargparse\u001b[0m\u001b[32m[\u001b[0m\u001b[32msignatures\u001b[0m\u001b[32m]\u001b[0m\u001b[32m>=4.17.0'\u001b[0m distribution was not found and is required by\n",
      "the application. HINT: Try running `pip install -U \n",
      "\u001b[32m'jsonargparse\u001b[0m\u001b[32m[\u001b[0m\u001b[32msignatures\u001b[0m\u001b[32m]\u001b[0m\u001b[32m>=4.17.0'\u001b[0m`. Try `pip install -U \n",
      "\u001b[32m'jsonargparse\u001b[0m\u001b[32m[\u001b[0m\u001b[32msignatures\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m`.\n"
     ]
    }
   ],
   "source": [
    "# Start the finetune model training\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    export WANDB_MODE=\"{WANDB_MODE}\" && \\\n",
    "    python3 lightning_trainer.py fit \\\n",
    "        -c \"{CONFIG_DIR}/config-mem-template.yaml\" \\\n",
    "        --trainer.logger.init_args.name=\"{WANDB_PREFIX} - Mem-Tune ctx-1024 (train-ctx=1024, {DEEPSPEED_STRAT})\" \\\n",
    "        --trainer.strategy=\"{DEEPSPEED_STRAT}\" \\\n",
    "        --trainer.devices=\"{GPU_DEVICES}\"  \\\n",
    "        --trainer.callbacks.init_args.dirpath=\"../checkpoint/{FILENAME_PREFIX}-mem-ctx-1024/\" \\\n",
    "        --model.lr_init=5e-4 \\\n",
    "        --model.lr_final=4e-4 \\\n",
    "        --data.max_token_size=1024 \\\n",
    "        --model.ctx_len=1024 \\\n",
    "        --model.bptt_learning_range=1 \\\n",
    "        --model.load_model=\"../model/{FILENAME_PREFIX}-mem-instruct.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets export the model from the checkpoint\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python3 export_checkpoint.py \\\n",
    "        \"../checkpoint/{FILENAME_PREFIX}-mem-ctx-1024/last.ckpt\" \\\n",
    "        \"../model/{FILENAME_PREFIX}-mem-ctx-1024.pth\" \"bf16\"\n",
    "!cd \"{TRAINER_DIR}\" && ls -alh \"../models/{FILENAME_PREFIX}-mem-ctx-1024.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets do a quick memory test\n",
    "!python3 ../../memory_script/eval_v5_memory_guided.py \"{PROJECT_DIR}/model/{FILENAME_PREFIX}-mem-ctx-1024.pth\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
